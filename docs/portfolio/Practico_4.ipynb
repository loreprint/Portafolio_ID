{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tarea 4: EDA Multi-fuentes y Joins - Fill in the Blanks¶"
   ],
   "metadata": {
    "id": "GxwMkTvtVWbD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Objetivos Básicos\n",
    "* Aprender a integrar datos de múltiples fuentes\n",
    "\n",
    "* Dominar los diferentes tipos de joins con pandas\n",
    "* Realizar análisis agregados con groupby\n",
    "* Crear reportes consolidados de datos integrados"
   ],
   "metadata": {
    "id": "oVSgXIs3VkO7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Paso 1: Setup Inicial: CONTEXTO DE NEGOCIO (CRISP-DM: Business Understanding)"
   ],
   "metadata": {
    "id": "zk2-Afx_VxRq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LENg3xxfU8n0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a3577171-3c3b-4aba-e643-b023306e111a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Setup completo para análisis multi-fuentes!\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías que vamos a usar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurar visualizaciones\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"✅ Setup completo para análisis multi-fuentes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 2 Carga de Datos desde Múltiples Fuentes\n"
   ],
   "metadata": {
    "id": "yGHmpRdDYejw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === CARGAR DATOS DE MÚLTIPLES FUENTES ===\n",
    "\n",
    "# 1. Cargar datos de viajes desde Parquet (Dataset oficial completo NYC)\n",
    "print(\"Cargando datos oficiales de NYC Taxi (dataset completo)...\")\n",
    "trips_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
    "\n",
    "# Cargar dataset oficial (~3M registros de enero 2023)\n",
    "trips = pd.read_parquet(trips_url)  # función para leer archivos .parquet (más eficiente que CSV) --read_parquet\n",
    "\n",
    "print(f\"   Viajes cargados: {trips.shape[0]:,} filas, {trips.shape[1]} columnas\")\n",
    "print(f\"   Columnas: {list(trips.columns)}\")\n",
    "print(f\"   Período: {trips['tpep_pickup_datetime'].min()} a {trips['tpep_pickup_datetime'].max()}\")\n",
    "print(f\"   Tamaño en memoria: {trips.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# 2. Cargar datos de zonas desde CSV (Dataset oficial completo)\n",
    "print(\"\\nCargando datos oficiales de zonas NYC...\")\n",
    "zones_url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\"\n",
    "zones = pd.read_csv(zones_url)  # función estándar para archivos CSV --read_csv\n",
    "\n",
    "print(f\"   Zonas cargadas: {zones.shape[0]} filas, {zones.shape[1]} columnas\")\n",
    "print(f\"   Columnas: {list(zones.columns)}\")\n",
    "print(f\"   Boroughs únicos: {zones['Borough'].unique()}\")\n",
    "\n",
    "# 3. Cargar calendario de eventos desde JSON\n",
    "print(\"\\nCargando datos de calendario de eventos...\")\n",
    "calendar_url = \"https://juanfkurucz.com/ucu-id/ut1/data/calendar.json\"\n",
    "calendar = pd.read_json(calendar_url)  # función para archivos JSON --read_json\n",
    "calendar['date'] = pd.to_datetime(calendar['date']).dt.date  # convertir strings a fechas, luego extraer solo la fecha\n",
    "\n",
    "print(f\"   Eventos calendario: {calendar.shape[0]} filas\")\n",
    "print(f\"   Columnas: {list(calendar.columns)}\")\n",
    "\n",
    "# 4. Mostrar primeras filas de cada dataset\n",
    "print(\"\\nVISTA PREVIA DE DATOS:\")\n",
    "print(\"\\n--- TRIPS ---\")\n",
    "print(trips.head())  # método para mostrar primeras filas de un DataFrame --HEAD\n",
    "print(\"\\n--- ZONES ---\")\n",
    "print(zones.describe())  # mismo método para ver estructura de datos -- DESCRIBE\n",
    "print(\"\\n--- CALENDAR ---\")\n",
    "print(calendar.info())  # revisar formato de los eventos -- INFO"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "KKR6idZqV68N",
    "outputId": "5bd2206f-424f-447f-b780-1fda7d928663"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cargando datos oficiales de NYC Taxi (dataset completo)...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1061445444.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Cargar dataset oficial (~3M registros de enero 2023)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrips_url\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# función para leer archivos .parquet (más eficiente que CSV) --read_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Viajes cargados: {trips.shape[0]:,} filas, {trips.shape[1]} columnas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "4beWblUcvYbu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 3: Normalización de Datos"
   ],
   "metadata": {
    "id": "CFdMDqlka65d"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === NORMALIZAR Y PREPARAR DATOS PARA JOINS ===\n",
    "\n",
    "# 1. Estandarizar nombres de columnas\n",
    "print(\"Normalizando nombres de columnas...\")\n",
    "trips.columns = trips.columns.str.lower()  # convertir todas las columnas a minúsculas\n",
    "zones.columns = zones.columns.str.lower()  # misma transformación para consistencia\n",
    "\n",
    "print(f\"   Trips columnas: {list(trips.columns)}\")\n",
    "print(f\"   Zones columnas: {list(zones.columns)}\")\n",
    "\n",
    "# 2. Crear columna de fecha para el join con calendario\n",
    "trips['pickup_date'] = trips['tpep_pickup_datetime'].dt.date  # extraer solo la fecha (sin hora) de la columna datetime\n",
    "\n",
    "print(f\"   Columna pickup_date creada\")\n",
    "print(f\"   Rango de fechas: {trips['pickup_date'].min()} a {trips['pickup_date'].max()}\")\n",
    "\n",
    "# 3. Verificar tipos de datos para joins\n",
    "print(\"\\nVERIFICACIÓN DE TIPOS PARA JOINS:\")\n",
    "print(f\"   trips['pulocationid'] tipo: {trips['pulocationid'].dtype}\")\n",
    "print(f\"   zones['locationid'] tipo: {zones['locationid'].dtype}\")\n",
    "print(f\"   trips['pickup_date'] tipo: {type(trips['pickup_date'].iloc[0])}\")\n",
    "print(f\"   calendar['date'] tipo: {type(calendar['date'].iloc[0])}\")\n",
    "\n",
    "# 4. Optimización para datasets grandes (~3M registros)\n",
    "print(\"\\nOPTIMIZACIÓN PARA DATASETS GRANDES:\")\n",
    "initial_memory = trips.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"   Memoria inicial: {initial_memory:.1f} MB\")\n",
    "\n",
    "# Optimizar tipos de datos para 3+ millones de registros\n",
    "print(\"   Optimizando tipos de datos para 3M+ registros...\")\n",
    "\n",
    "# Limpiar valores nulos antes de convertir tipos\n",
    "print(\"   Limpiando valores nulos antes de optimización...\")\n",
    "trips['passenger_count'] = trips['passenger_count'].fillna(0)  # método para rellenar valores nulos con un valor específico\n",
    "trips = trips.dropna(subset=['pulocationid', 'dolocationid'])  # eliminar filas críticas sin ubicación (necesarias para joins)\n",
    "\n",
    "# Convertir tipos después de limpiar\n",
    "trips['pulocationid'] = trips['pulocationid'].astype('int16')\n",
    "trips['dolocationid'] = trips['dolocationid'].astype('int16')\n",
    "trips['passenger_count'] = trips['passenger_count'].astype('int8')\n",
    "zones['locationid'] = zones['locationid'].astype('int16')\n",
    "\n",
    "print(f\"   Registros después de limpieza: {len(trips):,}\")\n",
    "\n",
    "optimized_memory = trips.memory_usage(deep=True).sum() / 1024**2\n",
    "savings = ((initial_memory - optimized_memory) / initial_memory * 100)\n",
    "\n",
    "print(f\"   Memoria optimizada: {optimized_memory:.1f} MB\")\n",
    "print(f\"   Ahorro de memoria: {savings:.1f}%\")\n",
    "\n",
    "# 5. Revisar datos faltantes antes de joins\n",
    "print(\"\\nDATOS FALTANTES ANTES DE JOINS:\")\n",
    "print(\"Trips (top 5 columnas con más nulos):\")\n",
    "trips_nulls = trips.isna().sum().sort_values(ascending=False).head()  # método para detectar valores nulos, sumar y ordenar\n",
    "print(trips_nulls)\n",
    "\n",
    "print(\"\\nZones:\")\n",
    "zones_nulls = zones.isna().sum()  # revisar si hay valores faltantes en lookup table\n",
    "print(zones_nulls)\n",
    "\n",
    "print(\"\\nCalendar:\")\n",
    "calendar_nulls = calendar.isna().sum()  # verificar integridad del calendario de eventos\n",
    "print(calendar_nulls)\n",
    "\n",
    "# Análisis de calidad de datos\n",
    "print(\"\\nANÁLISIS DE CALIDAD:\")\n",
    "total_trips = len(trips)\n",
    "print(f\"   Total de viajes: {total_trips:,}\")\n",
    "print(f\"   Viajes sin pickup location: {trips['pulocationid'].isna().sum():,}\")\n",
    "print(f\"   Viajes sin dropoff location: {trips['dolocationid'].isna().sum():,}\")\n",
    "print(f\"   Viajes sin passenger_count: {trips['passenger_count'].isna().sum():,}\")\n",
    "\n",
    "# Estrategias de limpieza recomendadas\n",
    "print(\"\\nESTRATEGIAS DE LIMPIEZA:\")\n",
    "print(\"   Ubicaciones nulas: Eliminar (crítico para joins)\")\n",
    "print(\"   Passenger_count nulos: Rellenar con valor típico (1)\")\n",
    "print(\"   Tarifas nulas: Revisar caso por caso\")"
   ],
   "metadata": {
    "id": "V6xdep7gY0VK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e8540b4d-2091-44b1-ff35-15b383f6621e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Normalizando nombres de columnas...\n",
      "   Trips columnas: ['vendorid', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'ratecodeid', 'store_and_fwd_flag', 'pulocationid', 'dolocationid', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
      "   Zones columnas: ['locationid', 'borough', 'zone', 'service_zone']\n",
      "   Columna pickup_date creada\n",
      "   Rango de fechas: 2008-12-31 a 2023-02-01\n",
      "\n",
      "VERIFICACIÓN DE TIPOS PARA JOINS:\n",
      "   trips['pulocationid'] tipo: int64\n",
      "   zones['locationid'] tipo: int64\n",
      "   trips['pickup_date'] tipo: <class 'datetime.date'>\n",
      "   calendar['date'] tipo: <class 'datetime.date'>\n",
      "\n",
      "OPTIMIZACIÓN PARA DATASETS GRANDES:\n",
      "   Memoria inicial: 682.6 MB\n",
      "   Optimizando tipos de datos para 3M+ registros...\n",
      "   Limpiando valores nulos antes de optimización...\n",
      "   Registros después de limpieza: 3,066,766\n",
      "   Memoria optimizada: 627.0 MB\n",
      "   Ahorro de memoria: 8.1%\n",
      "\n",
      "DATOS FALTANTES ANTES DE JOINS:\n",
      "Trips (top 5 columnas con más nulos):\n",
      "airport_fee             71743\n",
      "congestion_surcharge    71743\n",
      "store_and_fwd_flag      71743\n",
      "ratecodeid              71743\n",
      "passenger_count             0\n",
      "dtype: int64\n",
      "\n",
      "Zones:\n",
      "locationid      0\n",
      "borough         1\n",
      "zone            1\n",
      "service_zone    2\n",
      "dtype: int64\n",
      "\n",
      "Calendar:\n",
      "date       0\n",
      "name       0\n",
      "special    0\n",
      "dtype: int64\n",
      "\n",
      "ANÁLISIS DE CALIDAD:\n",
      "   Total de viajes: 3,066,766\n",
      "   Viajes sin pickup location: 0\n",
      "   Viajes sin dropoff location: 0\n",
      "   Viajes sin passenger_count: 0\n",
      "\n",
      "ESTRATEGIAS DE LIMPIEZA:\n",
      "   Ubicaciones nulas: Eliminar (crítico para joins)\n",
      "   Passenger_count nulos: Rellenar con valor típico (1)\n",
      "   Tarifas nulas: Revisar caso por caso\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Paso 4. Join Principal - Trips con Zones"
   ],
   "metadata": {
    "id": "FvO-fxNoaCuN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## === PRIMER JOIN: TRIPS + ZONES ===\n",
    "\n",
    "# 1. Hacer join de trips con zones para obtener información geográfica\n",
    "print(\"Realizando join: trips + zones...\")\n",
    "trips_with_zones = trips.merge(zones,   # método principal para unir DataFrames\n",
    "                                left_on='pulocationid',   # columna de trips que contiene ID de zona de pickup\n",
    "                                right_on='locationid',  # columna de zones que contiene ID correspondiente\n",
    "                                how='left')       # tipo de join que mantiene todos los trips\n",
    "\n",
    "print(f\"   Registros antes del join: {len(trips)}\")\n",
    "print(f\"   Registros después del join: {len(trips_with_zones)}\")\n",
    "print(f\"   Nuevas columnas añadidas: {[col for col in trips_with_zones.columns if col not in trips.columns]}\")\n",
    "\n",
    "# 2. Verificar el resultado del join\n",
    "print(\"\\nVERIFICACIÓN DEL JOIN:\")\n",
    "print(\"Conteo por Borough:\")\n",
    "print(trips_with_zones['borough'].value_counts())\n",
    "\n",
    "# 3. Verificar si hay valores nulos después del join\n",
    "null_after_join = trips_with_zones['borough'].isnull().sum()  # contar nulos en columna borough\n",
    "print(f\"\\nViajes sin borough asignado: {null_after_join}\")\n",
    "\n",
    "if null_after_join > 0:\n",
    "    print(\"   Algunos viajes no encontraron su zona correspondiente\")\n",
    "    print(\"   LocationIDs problemáticos:\")\n",
    "    problematic_ids = trips_with_zones[trips_with_zones['borough'].isnull()]['pulocationid'].unique()  # filtrar filas con nulos\n",
    "    print(f\"   {problematic_ids}\")\n",
    "\n",
    "# 4. Mostrar muestra del resultado\n",
    "print(\"\\nMUESTRA DEL DATASET INTEGRADO:\")\n",
    "print(trips_with_zones[['pulocationid', 'borough', 'zone', 'trip_distance', 'total_amount']].head())"
   ],
   "metadata": {
    "id": "eVKWWEIxaK0c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "13dace42-560b-499e-f71e-97c3d5a95653"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Realizando join: trips + zones...\n",
      "   Registros antes del join: 3066766\n",
      "   Registros después del join: 3066766\n",
      "   Nuevas columnas añadidas: ['locationid', 'borough', 'zone', 'service_zone']\n",
      "\n",
      "VERIFICACIÓN DEL JOIN:\n",
      "Conteo por Borough:\n",
      "borough\n",
      "Manhattan        2715369\n",
      "Queens            286645\n",
      "Unknown            40116\n",
      "Brooklyn           18076\n",
      "Bronx               4162\n",
      "EWR                  410\n",
      "Staten Island        341\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Viajes sin borough asignado: 1647\n",
      "   Algunos viajes no encontraron su zona correspondiente\n",
      "   LocationIDs problemáticos:\n",
      "   [265]\n",
      "\n",
      "MUESTRA DEL DATASET INTEGRADO:\n",
      "   pulocationid    borough               zone  trip_distance  total_amount\n",
      "0           161  Manhattan     Midtown Center           0.97         14.30\n",
      "1            43  Manhattan       Central Park           1.10         16.90\n",
      "2            48  Manhattan       Clinton East           2.51         34.90\n",
      "3           138     Queens  LaGuardia Airport           1.90         20.85\n",
      "4           107  Manhattan           Gramercy           1.43         19.68\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paso 5: Segundo Join - Agregar Datos de *Calendario*"
   ],
   "metadata": {
    "id": "JsBPWOktbtiA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === SEGUNDO JOIN: TRIPS_ZONES + CALENDAR ===\n",
    "\n",
    "# 1. Hacer join con datos de calendario\n",
    "print(\"Realizando join: trips_zones + calendar...\")\n",
    "trips_complete = trips_with_zones.merge(calendar,   # mismo método de join que antes\n",
    "                                         left_on='pickup_date',   # columna de fecha que creamos en trips\n",
    "                                         right_on='date',  # columna de fecha en calendar\n",
    "                                         how='left')       # tipo que mantiene todos los trips aunque no haya evento especial\n",
    "\n",
    "print(f\"   Registros antes del join: {len(trips_with_zones)}\")\n",
    "print(f\"   Registros después del join: {len(trips_complete)}\")\n",
    "\n",
    "# 2. Crear flag de evento especial\n",
    "trips_complete['is_special_day'] = trips_complete['special'].fillna('False')  # método para rellenar nulos con valor por defecto\n",
    "\n",
    "print(\"\\nDISTRIBUCIÓN DE DÍAS ESPECIALES:\")\n",
    "print(trips_complete['is_special_day'].value_counts())\n",
    "print(\"\\nEjemplos de eventos especiales:\")\n",
    "special_days = trips_complete[trips_complete['is_special_day'] == True]\n",
    "if len(special_days) > 0:\n",
    "    print(special_days[['pickup_date', 'special', 'borough']].drop_duplicates())\n",
    "else:\n",
    "    print(\"   No hay eventos especiales en este período\")\n",
    "\n",
    "# 3. Mostrar dataset final integrado\n",
    "print(\"\\nDATASET FINAL INTEGRADO:\")\n",
    "print(f\"   Total registros: {len(trips_complete)}\")\n",
    "print(f\"   Total columnas: {len(trips_complete.columns)}\")\n",
    "print(f\"   Columnas principales: {['borough', 'zone', 'is_special_day', 'trip_distance', 'total_amount']}\")\n",
    "\n",
    "# 4. Verificar integridad de los datos finales\n",
    "print(\"\\nVERIFICACIÓN FINAL:\")\n",
    "print(\"Datos faltantes por columna clave:\")\n",
    "key_columns = ['borough', 'zone', 'trip_distance', 'total_amount', 'is_special_day']\n",
    "for col in key_columns:\n",
    "    missing = trips_complete[col].isna().sum()  # verificar nulos en cada columna clave final\n",
    "    print(f\"   {col}: {missing} nulos\")"
   ],
   "metadata": {
    "id": "U6Xr-e23bzF1",
    "outputId": "05c09091-df16-4e2b-de05-429c284e2355",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Realizando join: trips_zones + calendar...\n",
      "   Registros antes del join: 3066766\n",
      "   Registros después del join: 3066766\n",
      "\n",
      "DISTRIBUCIÓN DE DÍAS ESPECIALES:\n",
      "is_special_day\n",
      "False    3066766\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ejemplos de eventos especiales:\n",
      "   No hay eventos especiales en este período\n",
      "\n",
      "DATASET FINAL INTEGRADO:\n",
      "   Total registros: 3066766\n",
      "   Total columnas: 28\n",
      "   Columnas principales: ['borough', 'zone', 'is_special_day', 'trip_distance', 'total_amount']\n",
      "\n",
      "VERIFICACIÓN FINAL:\n",
      "Datos faltantes por columna clave:\n",
      "   borough: 1647 nulos\n",
      "   zone: 40116 nulos\n",
      "   trip_distance: 0 nulos\n",
      "   total_amount: 0 nulos\n",
      "   is_special_day: 0 nulos\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paso 6: Analisis por Borough"
   ],
   "metadata": {
    "id": "4JkOPRZVcBUc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === ANÁLISIS AGREGADO POR BOROUGH ===\n",
    "\n",
    "# 1. Análisis básico por borough (con dataset grande)\n",
    "print(\"Análisis por Borough (procesando datos grandes)...\")\n",
    "borough_analysis = trips_complete.groupby(by='borough').agg({   # método para agrupar datos, por qué columna geográfica?\n",
    "    'pulocationid': 'count',  # función para contar número de registros/viajes\n",
    "    'trip_distance': ['mean', 'std', 'median'],  # función para promedio + desviación + mediana\n",
    "    'total_amount': ['mean', 'std', 'median'],   # mismas estadísticas para tarifas\n",
    "    'fare_amount': 'mean',     # solo promedio de tarifa base\n",
    "    'tip_amount': ['mean', 'median'],  # estadísticas de propinas\n",
    "    'passenger_count': 'mean'  # función para promedio de pasajeros\n",
    "}).round(2)\n",
    "\n",
    "# Aplanar columnas multi-nivel\n",
    "borough_analysis.columns = ['num_trips', 'avg_distance', 'std_distance', 'median_distance',\n",
    "                           'avg_total', 'std_total', 'median_total', 'avg_fare',\n",
    "                           'avg_tip', 'median_tip', 'avg_passengers']\n",
    "\n",
    "# Ordenar por número de viajes\n",
    "borough_analysis = borough_analysis.sort_values(by='num_trips', ascending=False)  # método para ordenar DataFrame por una columna específica\n",
    "\n",
    "print(\"\\nANÁLISIS COMPLETO POR BOROUGH:\")\n",
    "print(borough_analysis)\n",
    "\n",
    "# 2. Calcular métricas adicionales empresariales\n",
    "borough_analysis['revenue_per_km'] = (borough_analysis['avg_total'] /\n",
    "                                     borough_analysis['avg_distance']).round(2)\n",
    "borough_analysis['tip_rate'] = (borough_analysis['avg_tip'] /\n",
    "                               borough_analysis['avg_fare'] * 100).round(1)\n",
    "borough_analysis['market_share'] = (borough_analysis['num_trips'] /\n",
    "                                  borough_analysis['num_trips'].sum() * 100).round(1)\n",
    "\n",
    "print(\"\\nANÁLISIS CON MÉTRICAS EMPRESARIALES:\")\n",
    "print(borough_analysis[['num_trips', 'market_share', 'revenue_per_km', 'tip_rate']])\n",
    "\n",
    "# 3. Encontrar insights\n",
    "print(\"\\nINSIGHTS PRINCIPALES:\")\n",
    "print(f\"   Borough con más viajes: {borough_analysis.index[0]}\")\n",
    "print(f\"   Borough con viajes más largos: {borough_analysis['avg_distance'].idxmax()}\")\n",
    "print(f\"   Borough con tarifas más altas: {borough_analysis['avg_total'].idxmax()}\")\n",
    "print(f\"   Mejor revenue por km: {borough_analysis['revenue_per_km'].idxmax()}\")"
   ],
   "metadata": {
    "id": "h4hTs-g1cFeD",
    "outputId": "0d1859aa-5de9-47da-e053-1ab28a3e4160",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Análisis por Borough (procesando datos grandes)...\n",
      "\n",
      "ANÁLISIS COMPLETO POR BOROUGH:\n",
      "               num_trips  avg_distance  std_distance  median_distance  \\\n",
      "borough                                                                 \n",
      "Manhattan        2715369          2.88        264.53             1.63   \n",
      "Queens            286645         12.32         14.42            11.24   \n",
      "Unknown            40116          7.57        144.96             2.64   \n",
      "Brooklyn           18076          5.68         70.86             3.45   \n",
      "Bronx               4162          5.30          6.34             3.10   \n",
      "EWR                  410          1.59          5.68             0.00   \n",
      "Staten Island        341         11.36         10.21            14.80   \n",
      "\n",
      "               avg_total  std_total  median_total  avg_fare  avg_tip  \\\n",
      "borough                                                                \n",
      "Manhattan          22.49      14.54         19.25     14.78     2.88   \n",
      "Queens             67.27      33.64         70.35     49.98     7.85   \n",
      "Unknown            38.08      30.41         25.38     26.44     4.82   \n",
      "Brooklyn           33.02      22.56         28.64     26.81     2.94   \n",
      "Bronx              34.54      33.26         29.70     30.24     0.78   \n",
      "EWR               104.38      62.75        118.55     87.99    12.44   \n",
      "Staten Island      62.53      44.92         67.80     48.74     1.32   \n",
      "\n",
      "               median_tip  avg_passengers  \n",
      "borough                                    \n",
      "Manhattan            2.66            1.33  \n",
      "Queens               8.18            1.38  \n",
      "Unknown              3.14            1.34  \n",
      "Brooklyn             0.60            1.08  \n",
      "Bronx                0.00            1.03  \n",
      "EWR                 10.00            1.58  \n",
      "Staten Island        0.00            1.12  \n",
      "\n",
      "ANÁLISIS CON MÉTRICAS EMPRESARIALES:\n",
      "               num_trips  market_share  revenue_per_km  tip_rate\n",
      "borough                                                         \n",
      "Manhattan        2715369          88.6            7.81      19.5\n",
      "Queens            286645           9.4            5.46      15.7\n",
      "Unknown            40116           1.3            5.03      18.2\n",
      "Brooklyn           18076           0.6            5.81      11.0\n",
      "Bronx               4162           0.1            6.52       2.6\n",
      "EWR                  410           0.0           65.65      14.1\n",
      "Staten Island        341           0.0            5.50       2.7\n",
      "\n",
      "INSIGHTS PRINCIPALES:\n",
      "   Borough con más viajes: Manhattan\n",
      "   Borough con viajes más largos: Queens\n",
      "   Borough con tarifas más altas: EWR\n",
      "   Mejor revenue por km: EWR\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paso 7: Analisis por Borough y Dia especial"
   ],
   "metadata": {
    "id": "xiWBrvPydSdw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === ANÁLISIS COMPARATIVO: DÍAS NORMALES VS ESPECIALES ===\n",
    "\n",
    "# 1. Análisis por borough y tipo de día\n",
    "print(\"📅 Análisis: Borough + Día Especial...\")\n",
    "borough_day_analysis = trips_complete.groupby(by=['borough', 'is_special_day']).agg({  # agrupar por DOS columnas: geografía y tipo de día\n",
    "    'pulocationid': 'count',  # función para contar viajes\n",
    "    'trip_distance': 'mean',  # función para promedio de distancia\n",
    "    'total_amount': 'mean'    # función para promedio de tarifa\n",
    "}).round(2)\n",
    "\n",
    "borough_day_analysis.columns = ['num_trips', 'avg_distance', 'avg_total']\n",
    "\n",
    "print(\"\\n📊 ANÁLISIS BOROUGH + DÍA ESPECIAL:\")\n",
    "print(borough_day_analysis)\n",
    "\n",
    "# 2. Comparar días normales vs especiales\n",
    "print(\"\\n🔍 COMPARACIÓN DÍAS NORMALES VS ESPECIALES:\")\n",
    "\n",
    "# Pivotear para comparar fácilmente\n",
    "comparison = trips_complete.groupby(by='is_special_day').agg({  # agrupar solo por tipo de día para comparación general\n",
    "    'trip_distance': 'mean',    # promedio de distancia por tipo de día\n",
    "    'total_amount': 'mean',     # promedio de tarifa por tipo de día\n",
    "    'pulocationid': 'count'     # conteo de viajes por tipo de día\n",
    "}).round(2)\n",
    "\n",
    "# Renombrar índices según los valores únicos encontrados\n",
    "unique_day_types = comparison.index.tolist()\n",
    "if len(unique_day_types) == 2:\n",
    "    comparison.index = ['Día Normal', 'Día Especial']\n",
    "elif len(unique_day_types) == 1:\n",
    "    if unique_day_types[0] in ['False', False]:\n",
    "        comparison.index = ['Día Normal']\n",
    "    else:\n",
    "        comparison.index = ['Día Especial']\n",
    "\n",
    "comparison.columns = ['Avg Distance', 'Avg Amount', 'Num Trips']\n",
    "\n",
    "print(comparison)\n",
    "\n",
    "# 3. Calcular diferencias porcentuales\n",
    "if len(comparison) > 1:\n",
    "    # Hay tanto días normales como especiales\n",
    "    if 'Día Normal' in comparison.index and 'Día Especial' in comparison.index:\n",
    "        normal_day = comparison.loc['Día Normal']\n",
    "        special_day = comparison.loc['Día Especial']\n",
    "\n",
    "        print(\"\\nIMPACTO DE DÍAS ESPECIALES:\")\n",
    "        distance_change = ((special_day['Avg Distance'] - normal_day['Avg Distance']) / normal_day['Avg Distance'] * 100)\n",
    "        amount_change = ((special_day['Avg Amount'] - normal_day['Avg Amount']) / normal_day['Avg Amount'] * 100)\n",
    "\n",
    "        print(f\"   Cambio en distancia promedio: {distance_change:+.1f}%\")\n",
    "        print(f\"   Cambio en tarifa promedio: {amount_change:+.1f}%\")\n",
    "    else:\n",
    "        print(\"\\nINFORMACIÓN DE DÍAS:\")\n",
    "        for idx, row in comparison.iterrows():\n",
    "            print(f\"   {idx}: {row['Num Trips']:,} viajes, ${row['Avg Amount']:.2f} promedio\")\n",
    "else:\n",
    "    print(f\"\\nSOLO HAY {comparison.index[0]}:\")\n",
    "    print(f\"   Viajes: {comparison.iloc[0]['Num Trips']:,}\")\n",
    "    print(f\"   Distancia promedio: {comparison.iloc[0]['Avg Distance']:.2f} millas\")\n",
    "    print(f\"   Tarifa promedio: ${comparison.iloc[0]['Avg Amount']:.2f}\")\n",
    "    print(\"   No hay datos de días especiales para comparar en este período\")"
   ],
   "metadata": {
    "id": "f94aCpfAdhGi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ed791a8c-3a58-4311-f5ff-7aa5bc976e3e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "📅 Análisis: Borough + Día Especial...\n",
      "\n",
      "📊 ANÁLISIS BOROUGH + DÍA ESPECIAL:\n",
      "                              num_trips  avg_distance  avg_total\n",
      "borough       is_special_day                                    \n",
      "Bronx         False                4162          5.30      34.54\n",
      "Brooklyn      False               18076          5.68      33.02\n",
      "EWR           False                 410          1.59     104.38\n",
      "Manhattan     False             2715369          2.88      22.49\n",
      "Queens        False              286645         12.32      67.27\n",
      "Staten Island False                 341         11.36      62.53\n",
      "Unknown       False               40116          7.57      38.08\n",
      "\n",
      "🔍 COMPARACIÓN DÍAS NORMALES VS ESPECIALES:\n",
      "            Avg Distance  Avg Amount  Num Trips\n",
      "Día Normal          3.85       27.02    3066766\n",
      "\n",
      "SOLO HAY Día Normal:\n",
      "   Viajes: 3,066,766.0\n",
      "   Distancia promedio: 3.85 millas\n",
      "   Tarifa promedio: $27.02\n",
      "   No hay datos de días especiales para comparar en este período\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 8: Técnicas para Datasets Grandes"
   ],
   "metadata": {
    "id": "i67wz1gFeR4a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === TÉCNICAS PARA TRABAJAR CON DATASETS GRANDES ===\n",
    "\n",
    "# 1. Sampling estratégico para visualizaciones\n",
    "print(\"⚡ Aplicando técnicas para datasets grandes...\")\n",
    "\n",
    "# Si el dataset es muy grande, usar muestra para visualizaciones\n",
    "if len(trips_complete) > 50000:\n",
    "    print(f\"   📊 Dataset grande detectado: {len(trips_complete):,} registros\")\n",
    "    print(\"   🎯 Creando muestra estratificada para visualizaciones...\")\n",
    "\n",
    "    # Muestra proporcional por borough (simple aleatoria aquí)\n",
    "    sample_size = min(10000, len(trips_complete) // 10)\n",
    "    trips_sample = trips_complete.sample(n=sample_size, random_state=42)  # método para tomar muestra aleatoria de n registros\n",
    "\n",
    "    print(f\"   ✅ Muestra creada: {len(trips_sample):,} registros ({len(trips_sample)/len(trips_complete)*100:.1f}%)\")\n",
    "else:\n",
    "    trips_sample = trips_complete\n",
    "    print(\"   ℹ️ Dataset pequeño, usando datos completos para visualización\")\n",
    "\n",
    "# 2. Análisis de performance de joins\n",
    "print(\"\\n📈 ANÁLISIS DE PERFORMANCE:\")\n",
    "join_stats = {\n",
    "    'total_trips': len(trips),\n",
    "    'matched_zones': (trips_complete['borough'].notna()).sum(),\n",
    "    'match_rate': (trips_complete['borough'].notna().sum() / len(trips) * 100),\n",
    "    'unique_zones_used': trips_complete['zone'].nunique(),\n",
    "    'total_zones_available': len(zones),\n",
    "    'zone_coverage': (trips_complete['zone'].nunique() / len(zones) * 100)\n",
    "}\n",
    "\n",
    "for key, value in join_stats.items():\n",
    "    if 'rate' in key or 'coverage' in key:\n",
    "        print(f\"   {key}: {value:.1f}%\")\n",
    "    else:\n",
    "        print(f\"   {key}: {value:,}\")\n",
    "\n",
    "# 3. Análisis temporal avanzado (solo si hay suficientes datos)\n",
    "if len(trips_complete) > 1000:\n",
    "    print(\"\\n📅 ANÁLISIS TEMPORAL AVANZADO:\")\n",
    "\n",
    "    # Análisis por hora del día\n",
    "    trips_complete['pickup_hour'] = trips_complete['tpep_pickup_datetime'].dt.hour  # extraer hora de la fecha/hora\n",
    "    hourly_analysis = trips_complete.groupby(by='pickup_hour').agg({  # agrupar por hora del día\n",
    "        'pulocationid': 'count',     # contar viajes por hora (en minúsculas tras .str.lower())\n",
    "        'total_amount': 'mean',      # tarifa promedio por hora\n",
    "        'trip_distance': 'mean'      # distancia promedio por hora\n",
    "    }).round(2)\n",
    "\n",
    "    hourly_analysis.columns = ['trips_count', 'avg_amount', 'avg_distance']\n",
    "\n",
    "    print(\"   ⏰ Horas pico por número de viajes:\")\n",
    "    peak_hours = hourly_analysis.sort_values(by='trips_count', ascending=False).head(3)  # ordenar por más viajes, tomar top 3\n",
    "    for hour, stats in peak_hours.iterrows():\n",
    "        print(f\"      {hour:02d}:00 - {stats['trips_count']:,} viajes\")"
   ],
   "metadata": {
    "id": "e3UGHBqpe_-D",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7ab59e22-55b7-450a-cc2f-ba9829550802"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "⚡ Aplicando técnicas para datasets grandes...\n",
      "   📊 Dataset grande detectado: 3,066,766 registros\n",
      "   🎯 Creando muestra estratificada para visualizaciones...\n",
      "   ✅ Muestra creada: 10,000 registros (0.3%)\n",
      "\n",
      "📈 ANÁLISIS DE PERFORMANCE:\n",
      "   total_trips: 3,066,766\n",
      "   matched_zones: 3,065,119\n",
      "   match_rate: 99.9%\n",
      "   unique_zones_used: 255\n",
      "   total_zones_available: 265\n",
      "   zone_coverage: 96.2%\n",
      "\n",
      "📅 ANÁLISIS TEMPORAL AVANZADO:\n",
      "   ⏰ Horas pico por número de viajes:\n",
      "      18:00 - 215,889.0 viajes\n",
      "      17:00 - 209,493.0 viajes\n",
      "      15:00 - 196,424.0 viajes\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paso 9: Analisis de Correlaciones"
   ],
   "metadata": {
    "id": "49pCdplmenuz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === ANÁLISIS DE CORRELACIONES NUMÉRICAS ===\n",
    "\n",
    "# Calcular correlaciones entre variables numéricas\n",
    "print(\"Calculando correlaciones entre variables numéricas...\")\n",
    "numeric_cols = ['trip_distance', 'total_amount', 'fare_amount', 'tip_amount']\n",
    "corr_matrix = trips_complete[numeric_cols].corr()  # método para calcular matriz de correlación\n",
    "\n",
    "print(\"\\nMatriz de Correlación:\")\n",
    "print(corr_matrix.round(3))\n",
    "\n",
    "print(\"\\nCorrelaciones más fuertes:\")\n",
    "corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "\n",
    "corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "for var1, var2, corr in corr_pairs[:3]:\n",
    "    print(f\"   {var1} vs {var2}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\nINTERPRETACIÓN DE CORRELACIONES:\")\n",
    "print(\"   > 0.7: Correlación fuerte positiva\")\n",
    "print(\"   0.3-0.7: Correlación moderada positiva\")\n",
    "print(\"   -0.3-0.3: Correlación débil\")\n",
    "print(\"   < -0.7: Correlación fuerte negativa\")"
   ],
   "metadata": {
    "id": "iZSIOG1FdrTr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "39923ac6-e776-4403-e213-0971454342c4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculando correlaciones entre variables numéricas...\n",
      "\n",
      "Matriz de Correlación:\n",
      "               trip_distance  total_amount  fare_amount  tip_amount\n",
      "trip_distance          1.000         0.016        0.016       0.011\n",
      "total_amount           0.016         1.000        0.980       0.710\n",
      "fare_amount            0.016         0.980        1.000       0.590\n",
      "tip_amount             0.011         0.710        0.590       1.000\n",
      "\n",
      "Correlaciones más fuertes:\n",
      "   total_amount vs fare_amount: 0.980\n",
      "   total_amount vs tip_amount: 0.710\n",
      "   fare_amount vs tip_amount: 0.590\n",
      "\n",
      "INTERPRETACIÓN DE CORRELACIONES:\n",
      "   > 0.7: Correlación fuerte positiva\n",
      "   0.3-0.7: Correlación moderada positiva\n",
      "   -0.3-0.3: Correlación débil\n",
      "   < -0.7: Correlación fuerte negativa\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Responde estas preguntas después de completar el código:\n",
    "\n",
    "1. ¿Qué diferencia hay entre un LEFT JOIN y un INNER JOIN?  \n",
    "   Un left join\n",
    "\n",
    "El left join prioriza la persistencia de los datos que tiene la tabla de la izquierda - Recaba los datos relacionados con la tabla de la izquierda\n",
    "\n",
    "El right join prioriza la persistencia de los datos que tiene la tabla de la derecha - Recaba los datos relacionados con la tabla de la derecha\n",
    "\n",
    "El inner join realzia una cconjunción de ambas tablas, por lo que no hay una que esté más ponderada que la otra - Recaba los datos relacionados con ambas tablas\n",
    "\n",
    "2. ¿Por qué usamos LEFT JOIN en lugar de INNER JOIN para trips+zones?\n",
    "\n",
    "Esto se debe a que priorizamos los registros de viajes, antes que los de zonas, hay algunos registros cuyo PULocationID no están relacionados a una zona.\n",
    "Si ponderamos la zona perderíamos viajes asociados a ellas.  \n",
    "\n",
    "3. ¿Qué problemas pueden surgir al hacer joins con datos de fechas?\n",
    "\n",
    "En caso de que el formato de las fechas sea distinto esto generaría conflicto\n",
    "También pueden darse problemas debido a un desfase horario u errores de especificación de las fechas\n",
    "A su vez las fechas que están en nul generan pérdidades totales de registros en la consulta realizada\n",
    "\n",
    "En sí todo recae en que el dato fecha es un dato que tiene demasiados formatos, y varía mucho de dataset en dataset, primero se debe normalizar y estandarizar los datos, generando un formato único para realziar el análisis.\n",
    "\n",
    "4. ¿Cuál es la ventaja de integrar múltiples fuentes de datos?\n",
    "\n",
    "La complejidad de los mismos, nos permite realizar un análisis más amplio, manejando un repertorio de datos más grande.\n",
    "\n",
    "\n",
    "5. ¿Qué insights de negocio obtuviste del análisis integrado?\n",
    "Concentración de la demanda por zona. Un borough concentra la mayor cantidad de viajes (mayor market share), lo que indica dónde priorizar flota y puntos de espera.\n",
    "\n",
    "Viajes más largos fuera del centro. En los boroughs menos centrales la distancia promedio es mayor, útil para planificar tarifas, disponibilidad y tiempos de servicio.\n",
    "\n",
    "Eficiencia de ingresos. Hay diferencias claras en revenue por km entre boroughs; priorizar las zonas con mejor relación ingreso/distancia mejora el margen.\n"
   ],
   "metadata": {
    "id": "peTazWt9kXim"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BONUS: Introducción a Prefect"
   ],
   "metadata": {
    "id": "2RSzJ1Xvvb6L"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 1: Setup Básico"
   ],
   "metadata": {
    "id": "sLQ5AH3svdvw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === SETUP PREFECT ===\n",
    "\n",
    "# Instalar Prefect (si no está instalado)\n",
    "!pip install prefect\n",
    "\n",
    "import prefect\n",
    "from prefect import task, flow, get_run_logger\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Prefect instalado y configurado\")\n",
    "print(f\"   Versión: {prefect.__version__}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyDtYrYXviCX",
    "outputId": "130e60a3-0fd8-4b1b-f757-06ff93340588"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: prefect in /usr/local/lib/python3.12/dist-packages (3.4.14)\n",
      "Requirement already satisfied: aiosqlite<1.0.0,>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.21.0)\n",
      "Requirement already satisfied: alembic<2.0.0,>=1.7.5 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.16.4)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (4.10.0)\n",
      "Requirement already satisfied: apprise<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.9.4)\n",
      "Requirement already satisfied: asgi-lifespan<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.1.0)\n",
      "Requirement already satisfied: asyncpg<1.0.0,>=0.23 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.30.0)\n",
      "Requirement already satisfied: cachetools<7.0,>=5.3 in /usr/local/lib/python3.12/dist-packages (from prefect) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=8.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (3.1.1)\n",
      "Requirement already satisfied: coolname<3.0.0,>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.2.0)\n",
      "Requirement already satisfied: cryptography>=36.0.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (43.0.3)\n",
      "Requirement already satisfied: dateparser<2.0.0,>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.2.2)\n",
      "Requirement already satisfied: docker<8.0,>=4.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (7.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.3.0)\n",
      "Requirement already satisfied: fastapi<1.0.0,>=0.111.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.116.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (2025.3.0)\n",
      "Requirement already satisfied: graphviz>=0.20.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.21)\n",
      "Requirement already satisfied: griffe<2.0.0,>=0.49.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.13.0)\n",
      "Requirement already satisfied: httpcore<2.0.0,>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.0.9)\n",
      "Requirement already satisfied: httpx!=0.23.2,>=0.23 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]!=0.23.2,>=0.23->prefect) (0.28.1)\n",
      "Requirement already satisfied: humanize<5.0.0,>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (4.12.3)\n",
      "Requirement already satisfied: jinja2-humanize-extension>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.4.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.6 in /usr/local/lib/python3.12/dist-packages (from prefect) (3.1.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.32 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.33)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (4.25.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.27.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.36.0)\n",
      "Requirement already satisfied: orjson<4.0,>=3.7 in /usr/local/lib/python3.12/dist-packages (from prefect) (3.11.2)\n",
      "Requirement already satisfied: packaging<25.1,>=21.3 in /usr/local/lib/python3.12/dist-packages (from prefect) (25.0)\n",
      "Requirement already satisfied: pathspec>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.12.1)\n",
      "Requirement already satisfied: pendulum<4,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (3.1.0)\n",
      "Requirement already satisfied: prometheus-client>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.22.1)\n",
      "Requirement already satisfied: pydantic!=2.11.0,!=2.11.1,!=2.11.2,!=2.11.3,!=2.11.4,<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.11.7)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.33.2)\n",
      "Requirement already satisfied: pydantic-extra-types<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.10.5)\n",
      "Requirement already satisfied: pydantic-settings!=2.9.0,<3.0.0,>2.2.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify<9.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (8.0.4)\n",
      "Requirement already satisfied: python-socks<3.0,>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from python-socks[asyncio]<3.0,>=2.5.3->prefect) (2.7.2)\n",
      "Requirement already satisfied: pytz<2026,>=2021.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (2025.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (6.0.2)\n",
      "Requirement already satisfied: readchar<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (4.2.1)\n",
      "Requirement already satisfied: rfc3339-validator<0.2.0,>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.1.4)\n",
      "Requirement already satisfied: rich<15.0,>=11.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (13.9.4)\n",
      "Requirement already satisfied: ruamel-yaml>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.18.15)\n",
      "Requirement already satisfied: semver>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from prefect) (3.0.4)\n",
      "Requirement already satisfied: sniffio<2.0.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.3.1)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]<3.0.0,>=2.0->prefect) (2.0.43)\n",
      "Requirement already satisfied: toml>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.10.2)\n",
      "Requirement already satisfied: typer!=0.12.2,<0.17.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (4.14.1)\n",
      "Requirement already satisfied: uv>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.8.13)\n",
      "Requirement already satisfied: uvicorn!=0.29.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.35.0)\n",
      "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (15.0.1)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2.0.0,>=1.7.5->prefect) (1.1.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.4.0->prefect) (3.10)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (2.32.4)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (2.0.0)\n",
      "Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (3.8.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (2025.8.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.1->prefect) (1.17.1)\n",
      "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser<2.0.0,>=1.1.1->prefect) (2024.11.6)\n",
      "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser<2.0.0,>=1.1.1->prefect) (5.3.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8.0,>=4.0->prefect) (2.5.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0.0,>=0.111.0->prefect) (0.47.2)\n",
      "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe<2.0.0,>=0.49.0->prefect) (0.4.6)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore<2.0.0,>=1.0.5->prefect) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]!=0.23.2,>=0.23->prefect) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.6->prefect) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.32->prefect) (3.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.18.0->prefect) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.18.0->prefect) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.18.0->prefect) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.18.0->prefect) (0.27.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.27.0->prefect) (8.7.0)\n",
      "Requirement already satisfied: tzdata>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pendulum<4,>=3.0.0->prefect) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.11.0,!=2.11.1,!=2.11.2,!=2.11.3,!=2.11.4,<3.0.0,>=2.10.1->prefect) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.11.0,!=2.11.1,!=2.11.2,!=2.11.3,!=2.11.4,<3.0.0,>=2.10.1->prefect) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings!=2.9.0,<3.0.0,>2.2.1->prefect) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->prefect) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.12/dist-packages (from python-slugify<9.0,>=5.0->prefect) (1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0,>=11.0->prefect) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0,>=11.0->prefect) (2.19.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from ruamel-yaml>=0.17.0->prefect) (0.2.12)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3.0.0,>=2.0->sqlalchemy[asyncio]<3.0.0,>=2.0->prefect) (3.2.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer!=0.12.2,<0.17.0,>=0.12.0->prefect) (1.5.4)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.1->prefect) (2.22)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]!=0.23.2,>=0.23->prefect) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]!=0.23.2,>=0.23->prefect) (4.1.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.27.0->prefect) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0,>=11.0->prefect) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->apprise<2.0.0,>=1.1.0->prefect) (3.4.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->apprise<2.0.0,>=1.1.0->prefect) (3.3.1)\n",
      "Prefect instalado y configurado\n",
      "   Versión: 3.4.14\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 2: Convertir funciones a tasks"
   ],
   "metadata": {
    "id": "0THYCSQVvlPS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === TASKS SIMPLES PARA APRENDER PREFECT ===\n",
    "\n",
    "@task(name=\"Cargar Datos\", retries=2, retry_delay_seconds=3)\n",
    "def cargar_datos(url: str, tipo: str) -> pd.DataFrame:\n",
    "    \"\"\"Task simple para cargar cualquier tipo de datos\"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(f\"Cargando {tipo} desde: {url}\")\n",
    "\n",
    "    # Cargar según el tipo\n",
    "    if tipo == \"trips\":\n",
    "        data = pd.read_parquet(url)  # función para Parquet\n",
    "    elif tipo == \"zones\":\n",
    "        data = pd.read_csv(url)      # función para CSV\n",
    "    else:  # calendar\n",
    "        data = pd.read_json(url)     # función para JSON\n",
    "        data['date'] = pd.to_datetime(data['date']).dt.date  # convertir strings a fechas\n",
    "\n",
    "    logger.info(f\"{tipo} cargado: {data.shape[0]} filas\")\n",
    "    return data\n",
    "\n",
    "\n",
    "@task(name=\"Hacer Join Simple\")\n",
    "def hacer_join_simple(trips: pd.DataFrame, zones: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Task para hacer join básico de trips + zones\"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Haciendo join simple...\")\n",
    "\n",
    "    # Normalizar columnas\n",
    "    trips.columns = trips.columns.str.lower()   # convertir a minúsculas\n",
    "    zones.columns = zones.columns.str.lower()   # misma transformación\n",
    "\n",
    "    # Join básico\n",
    "    resultado = trips.merge(zones,              # método para unir DataFrames\n",
    "                            left_on='pulocationid',   # columna de pickup location en trips\n",
    "                            right_on='locationid',    # columna de location en zones\n",
    "                            how='left')               # tipo de join que mantiene todos los trips\n",
    "\n",
    "    logger.info(f\"Join completado: {len(resultado)} registros\")\n",
    "    return resultado\n",
    "\n",
    "\n",
    "@task(name=\"Análisis Rápido\")\n",
    "def analisis_rapido(data: pd.DataFrame) -> dict:\n",
    "    \"\"\"Task para análisis básico\"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Haciendo análisis básico...\")\n",
    "\n",
    "    # Stats simples\n",
    "    stats = {\n",
    "        'total_registros': len(data),  # método para contar valores\n",
    "        'boroughs': data['borough'].value_counts().head(3).to_dict(),  # contar valores únicos\n",
    "        'distancia_promedio': round(data['trip_distance'].mean(), 2),  # método para promedio\n",
    "        'tarifa_promedio': round(data['total_amount'].mean(), 2)       # método para promedio\n",
    "    }\n",
    "\n",
    "    logger.info(f\"Análisis completado: {stats['total_registros']} registros\")\n",
    "    return stats"
   ],
   "metadata": {
    "id": "P1rHRiIqvj3c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 3: Crear un flow simple"
   ],
   "metadata": {
    "id": "Lm4XuZcLvrn1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === FLOW PRINCIPAL (EL PIPELINE COMPLETO) ===\n",
    "\n",
    "@flow(name=\"Pipeline Simple NYC Taxi\")\n",
    "def pipeline_taxi_simple():\n",
    "    \"\"\"Flow simple que conecta todos los tasks\"\"\"\n",
    "\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Iniciando pipeline simple...\")\n",
    "\n",
    "    # URLs de datos\n",
    "    trips_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
    "    zones_url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\"\n",
    "\n",
    "    # PASO 1: Cargar datos (con retry automático si falla)\n",
    "    logger.info(\"Paso 1: Cargando datos...\")\n",
    "    trips = cargar_datos(trips_url, \"trips\")    # tipo de datos = trips\n",
    "    zones = cargar_datos(zones_url, \"zones\")    # tipo de datos = zones\n",
    "\n",
    "    # PASO 2: Hacer join\n",
    "    logger.info(\"Paso 2: Haciendo join...\")\n",
    "    data_unida = hacer_join_simple(trips, zones)\n",
    "\n",
    "    # PASO 3: Análisis básico\n",
    "    logger.info(\"Paso 3: Analizando...\")\n",
    "    resultados = analisis_rapido(data_unida)\n",
    "\n",
    "    # PASO 4: Mostrar resultados\n",
    "    logger.info(\"Pipeline completado!\")\n",
    "    logger.info(f\"Resultados: {resultados}\")\n",
    "\n",
    "    return resultados"
   ],
   "metadata": {
    "id": "MVtX17WfvsP_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 4: Ejecutar el Pipeline"
   ],
   "metadata": {
    "id": "D5MOR7UpvujO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === EJECUTAR EL PIPELINE ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🚀 Ejecutando pipeline simple...\")\n",
    "\n",
    "    # Ejecutar el flow\n",
    "    resultado = pipeline_taxi_simple()   # nombre de la función del flow\n",
    "\n",
    "    print(\"\\n📊 RESULTADOS FINALES:\")\n",
    "    print(f\" Total registros: {resultado['total_registros']}\")\n",
    "    print(f\" Distancia promedio: {resultado['distancia_promedio']} millas\")\n",
    "    print(f\" Tarifa promedio: ${resultado['tarifa_promedio']}\")\n",
    "\n",
    "    print(\"\\n🏙️ Top 3 Boroughs:\")\n",
    "    for borough, count in resultado['boroughs'].items():  # clave del diccionario que contiene boroughs\n",
    "        print(f\" {borough}: {count} viajes\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "Ok-tq2v6vwXO",
    "outputId": "eeced601-13fe-49b0-c523-ca8e5c15ae38"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🚀 Ejecutando pipeline simple...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:19.946 | \u001b[36mINFO\u001b[0m    | prefect - Starting temporary server on \u001b[94mhttp://127.0.0.1:8916\u001b[0m\n",
       "See \u001b[94mhttps://docs.prefect.io/v3/concepts/server#how-to-guides\u001b[0m for more information on running a dedicated Prefect server.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:19.946 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect - Starting temporary server on <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:8916</span>\n",
       "See <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://docs.prefect.io/v3/concepts/server#how-to-guides</span> for more information on running a dedicated Prefect server.\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:20.572 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Beginning flow run\u001b[35m 'bouncy-jaguar'\u001b[0m for flow\u001b[1;35m 'Pipeline Simple NYC Taxi'\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:20.572 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Pipeline Simple NYC Taxi'</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:20.584 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Iniciando pipeline simple...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:20.584 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Iniciando pipeline simple...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:20.586 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Paso 1: Cargando datos...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:20.586 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Paso 1: Cargando datos...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:20.836 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-f06' - Cargando trips desde: \u001b[94mhttps://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:20.836 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-f06' - Cargando trips desde: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.571 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-f06' - trips cargado: 3066766 filas\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.571 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-f06' - trips cargado: 3066766 filas\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.594 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-f06' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.594 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-f06' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.849 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-e5e' - Cargando zones desde: \u001b[94mhttps://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.849 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-e5e' - Cargando zones desde: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.891 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-e5e' - zones cargado: 265 filas\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.891 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-e5e' - zones cargado: 265 filas\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.900 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-e5e' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.900 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-e5e' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.912 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Paso 2: Haciendo join...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.912 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Paso 2: Haciendo join...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:29.043 | \u001b[36mINFO\u001b[0m    | Task run 'Hacer Join Simple-c2a' - Haciendo join simple...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:29.043 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Hacer Join Simple-c2a' - Haciendo join simple...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:31.600 | \u001b[36mINFO\u001b[0m    | Task run 'Hacer Join Simple-c2a' - Join completado: 3066766 registros\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:31.600 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Hacer Join Simple-c2a' - Join completado: 3066766 registros\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:31.628 | \u001b[36mINFO\u001b[0m    | Task run 'Hacer Join Simple-c2a' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:31.628 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Hacer Join Simple-c2a' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:31.638 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Paso 3: Analizando...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:31.638 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Paso 3: Analizando...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:36.913 | \u001b[36mINFO\u001b[0m    | Task run 'Análisis Rápido-6bd' - Haciendo análisis básico...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:36.913 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Análisis Rápido-6bd' - Haciendo análisis básico...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:37.536 | \u001b[36mINFO\u001b[0m    | Task run 'Análisis Rápido-6bd' - Análisis completado: 3066766 registros\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:37.536 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Análisis Rápido-6bd' - Análisis completado: 3066766 registros\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:37.553 | \u001b[36mINFO\u001b[0m    | Task run 'Análisis Rápido-6bd' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:37.553 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Análisis Rápido-6bd' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:37.562 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Pipeline completado!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:37.562 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Pipeline completado!\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:37.573 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Resultados: {'total_registros': 3066766, 'boroughs': {'Manhattan': 2715369, 'Queens': 286645, 'Unknown': 40116}, 'distancia_promedio': np.float64(3.85), 'tarifa_promedio': np.float64(27.02)}\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:37.573 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Resultados: {'total_registros': 3066766, 'boroughs': {'Manhattan': 2715369, 'Queens': 286645, 'Unknown': 40116}, 'distancia_promedio': np.float64(3.85), 'tarifa_promedio': np.float64(27.02)}\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:37.874 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:37.874 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "📊 RESULTADOS FINALES:\n",
      " Total registros: 3066766\n",
      " Distancia promedio: 3.85 millas\n",
      " Tarifa promedio: $27.02\n",
      "\n",
      "🏙️ Top 3 Boroughs:\n",
      " Manhattan: 2715369 viajes\n",
      " Queens: 286645 viajes\n",
      " Unknown: 40116 viajes\n"
     ]
    }
   ]
  }
 ]
}