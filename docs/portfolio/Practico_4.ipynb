{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tarea 4: EDA Multi-fuentes y Joins - Fill in the Blanks¬∂"
   ],
   "metadata": {
    "id": "GxwMkTvtVWbD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Objetivos B√°sicos\n",
    "* Aprender a integrar datos de m√∫ltiples fuentes\n",
    "\n",
    "* Dominar los diferentes tipos de joins con pandas\n",
    "* Realizar an√°lisis agregados con groupby\n",
    "* Crear reportes consolidados de datos integrados"
   ],
   "metadata": {
    "id": "oVSgXIs3VkO7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Paso 1: Setup Inicial: CONTEXTO DE NEGOCIO (CRISP-DM: Business Understanding)"
   ],
   "metadata": {
    "id": "zk2-Afx_VxRq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LENg3xxfU8n0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a3577171-3c3b-4aba-e643-b023306e111a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Setup completo para an√°lisis multi-fuentes!\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as que vamos a usar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurar visualizaciones\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"‚úÖ Setup completo para an√°lisis multi-fuentes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 2 Carga de Datos desde M√∫ltiples Fuentes\n"
   ],
   "metadata": {
    "id": "yGHmpRdDYejw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === CARGAR DATOS DE M√öLTIPLES FUENTES ===\n",
    "\n",
    "# 1. Cargar datos de viajes desde Parquet (Dataset oficial completo NYC)\n",
    "print(\"Cargando datos oficiales de NYC Taxi (dataset completo)...\")\n",
    "trips_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
    "\n",
    "# Cargar dataset oficial (~3M registros de enero 2023)\n",
    "trips = pd.read_parquet(trips_url)  # funci√≥n para leer archivos .parquet (m√°s eficiente que CSV) --read_parquet\n",
    "\n",
    "print(f\"   Viajes cargados: {trips.shape[0]:,} filas, {trips.shape[1]} columnas\")\n",
    "print(f\"   Columnas: {list(trips.columns)}\")\n",
    "print(f\"   Per√≠odo: {trips['tpep_pickup_datetime'].min()} a {trips['tpep_pickup_datetime'].max()}\")\n",
    "print(f\"   Tama√±o en memoria: {trips.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# 2. Cargar datos de zonas desde CSV (Dataset oficial completo)\n",
    "print(\"\\nCargando datos oficiales de zonas NYC...\")\n",
    "zones_url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\"\n",
    "zones = pd.read_csv(zones_url)  # funci√≥n est√°ndar para archivos CSV --read_csv\n",
    "\n",
    "print(f\"   Zonas cargadas: {zones.shape[0]} filas, {zones.shape[1]} columnas\")\n",
    "print(f\"   Columnas: {list(zones.columns)}\")\n",
    "print(f\"   Boroughs √∫nicos: {zones['Borough'].unique()}\")\n",
    "\n",
    "# 3. Cargar calendario de eventos desde JSON\n",
    "print(\"\\nCargando datos de calendario de eventos...\")\n",
    "calendar_url = \"https://juanfkurucz.com/ucu-id/ut1/data/calendar.json\"\n",
    "calendar = pd.read_json(calendar_url)  # funci√≥n para archivos JSON --read_json\n",
    "calendar['date'] = pd.to_datetime(calendar['date']).dt.date  # convertir strings a fechas, luego extraer solo la fecha\n",
    "\n",
    "print(f\"   Eventos calendario: {calendar.shape[0]} filas\")\n",
    "print(f\"   Columnas: {list(calendar.columns)}\")\n",
    "\n",
    "# 4. Mostrar primeras filas de cada dataset\n",
    "print(\"\\nVISTA PREVIA DE DATOS:\")\n",
    "print(\"\\n--- TRIPS ---\")\n",
    "print(trips.head())  # m√©todo para mostrar primeras filas de un DataFrame --HEAD\n",
    "print(\"\\n--- ZONES ---\")\n",
    "print(zones.describe())  # mismo m√©todo para ver estructura de datos -- DESCRIBE\n",
    "print(\"\\n--- CALENDAR ---\")\n",
    "print(calendar.info())  # revisar formato de los eventos -- INFO"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "KKR6idZqV68N",
    "outputId": "5bd2206f-424f-447f-b780-1fda7d928663"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cargando datos oficiales de NYC Taxi (dataset completo)...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1061445444.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Cargar dataset oficial (~3M registros de enero 2023)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrips_url\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# funci√≥n para leer archivos .parquet (m√°s eficiente que CSV) --read_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Viajes cargados: {trips.shape[0]:,} filas, {trips.shape[1]} columnas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "4beWblUcvYbu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 3: Normalizaci√≥n de Datos"
   ],
   "metadata": {
    "id": "CFdMDqlka65d"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === NORMALIZAR Y PREPARAR DATOS PARA JOINS ===\n",
    "\n",
    "# 1. Estandarizar nombres de columnas\n",
    "print(\"Normalizando nombres de columnas...\")\n",
    "trips.columns = trips.columns.str.lower()  # convertir todas las columnas a min√∫sculas\n",
    "zones.columns = zones.columns.str.lower()  # misma transformaci√≥n para consistencia\n",
    "\n",
    "print(f\"   Trips columnas: {list(trips.columns)}\")\n",
    "print(f\"   Zones columnas: {list(zones.columns)}\")\n",
    "\n",
    "# 2. Crear columna de fecha para el join con calendario\n",
    "trips['pickup_date'] = trips['tpep_pickup_datetime'].dt.date  # extraer solo la fecha (sin hora) de la columna datetime\n",
    "\n",
    "print(f\"   Columna pickup_date creada\")\n",
    "print(f\"   Rango de fechas: {trips['pickup_date'].min()} a {trips['pickup_date'].max()}\")\n",
    "\n",
    "# 3. Verificar tipos de datos para joins\n",
    "print(\"\\nVERIFICACI√ìN DE TIPOS PARA JOINS:\")\n",
    "print(f\"   trips['pulocationid'] tipo: {trips['pulocationid'].dtype}\")\n",
    "print(f\"   zones['locationid'] tipo: {zones['locationid'].dtype}\")\n",
    "print(f\"   trips['pickup_date'] tipo: {type(trips['pickup_date'].iloc[0])}\")\n",
    "print(f\"   calendar['date'] tipo: {type(calendar['date'].iloc[0])}\")\n",
    "\n",
    "# 4. Optimizaci√≥n para datasets grandes (~3M registros)\n",
    "print(\"\\nOPTIMIZACI√ìN PARA DATASETS GRANDES:\")\n",
    "initial_memory = trips.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"   Memoria inicial: {initial_memory:.1f} MB\")\n",
    "\n",
    "# Optimizar tipos de datos para 3+ millones de registros\n",
    "print(\"   Optimizando tipos de datos para 3M+ registros...\")\n",
    "\n",
    "# Limpiar valores nulos antes de convertir tipos\n",
    "print(\"   Limpiando valores nulos antes de optimizaci√≥n...\")\n",
    "trips['passenger_count'] = trips['passenger_count'].fillna(0)  # m√©todo para rellenar valores nulos con un valor espec√≠fico\n",
    "trips = trips.dropna(subset=['pulocationid', 'dolocationid'])  # eliminar filas cr√≠ticas sin ubicaci√≥n (necesarias para joins)\n",
    "\n",
    "# Convertir tipos despu√©s de limpiar\n",
    "trips['pulocationid'] = trips['pulocationid'].astype('int16')\n",
    "trips['dolocationid'] = trips['dolocationid'].astype('int16')\n",
    "trips['passenger_count'] = trips['passenger_count'].astype('int8')\n",
    "zones['locationid'] = zones['locationid'].astype('int16')\n",
    "\n",
    "print(f\"   Registros despu√©s de limpieza: {len(trips):,}\")\n",
    "\n",
    "optimized_memory = trips.memory_usage(deep=True).sum() / 1024**2\n",
    "savings = ((initial_memory - optimized_memory) / initial_memory * 100)\n",
    "\n",
    "print(f\"   Memoria optimizada: {optimized_memory:.1f} MB\")\n",
    "print(f\"   Ahorro de memoria: {savings:.1f}%\")\n",
    "\n",
    "# 5. Revisar datos faltantes antes de joins\n",
    "print(\"\\nDATOS FALTANTES ANTES DE JOINS:\")\n",
    "print(\"Trips (top 5 columnas con m√°s nulos):\")\n",
    "trips_nulls = trips.isna().sum().sort_values(ascending=False).head()  # m√©todo para detectar valores nulos, sumar y ordenar\n",
    "print(trips_nulls)\n",
    "\n",
    "print(\"\\nZones:\")\n",
    "zones_nulls = zones.isna().sum()  # revisar si hay valores faltantes en lookup table\n",
    "print(zones_nulls)\n",
    "\n",
    "print(\"\\nCalendar:\")\n",
    "calendar_nulls = calendar.isna().sum()  # verificar integridad del calendario de eventos\n",
    "print(calendar_nulls)\n",
    "\n",
    "# An√°lisis de calidad de datos\n",
    "print(\"\\nAN√ÅLISIS DE CALIDAD:\")\n",
    "total_trips = len(trips)\n",
    "print(f\"   Total de viajes: {total_trips:,}\")\n",
    "print(f\"   Viajes sin pickup location: {trips['pulocationid'].isna().sum():,}\")\n",
    "print(f\"   Viajes sin dropoff location: {trips['dolocationid'].isna().sum():,}\")\n",
    "print(f\"   Viajes sin passenger_count: {trips['passenger_count'].isna().sum():,}\")\n",
    "\n",
    "# Estrategias de limpieza recomendadas\n",
    "print(\"\\nESTRATEGIAS DE LIMPIEZA:\")\n",
    "print(\"   Ubicaciones nulas: Eliminar (cr√≠tico para joins)\")\n",
    "print(\"   Passenger_count nulos: Rellenar con valor t√≠pico (1)\")\n",
    "print(\"   Tarifas nulas: Revisar caso por caso\")"
   ],
   "metadata": {
    "id": "V6xdep7gY0VK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e8540b4d-2091-44b1-ff35-15b383f6621e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Normalizando nombres de columnas...\n",
      "   Trips columnas: ['vendorid', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'ratecodeid', 'store_and_fwd_flag', 'pulocationid', 'dolocationid', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
      "   Zones columnas: ['locationid', 'borough', 'zone', 'service_zone']\n",
      "   Columna pickup_date creada\n",
      "   Rango de fechas: 2008-12-31 a 2023-02-01\n",
      "\n",
      "VERIFICACI√ìN DE TIPOS PARA JOINS:\n",
      "   trips['pulocationid'] tipo: int64\n",
      "   zones['locationid'] tipo: int64\n",
      "   trips['pickup_date'] tipo: <class 'datetime.date'>\n",
      "   calendar['date'] tipo: <class 'datetime.date'>\n",
      "\n",
      "OPTIMIZACI√ìN PARA DATASETS GRANDES:\n",
      "   Memoria inicial: 682.6 MB\n",
      "   Optimizando tipos de datos para 3M+ registros...\n",
      "   Limpiando valores nulos antes de optimizaci√≥n...\n",
      "   Registros despu√©s de limpieza: 3,066,766\n",
      "   Memoria optimizada: 627.0 MB\n",
      "   Ahorro de memoria: 8.1%\n",
      "\n",
      "DATOS FALTANTES ANTES DE JOINS:\n",
      "Trips (top 5 columnas con m√°s nulos):\n",
      "airport_fee             71743\n",
      "congestion_surcharge    71743\n",
      "store_and_fwd_flag      71743\n",
      "ratecodeid              71743\n",
      "passenger_count             0\n",
      "dtype: int64\n",
      "\n",
      "Zones:\n",
      "locationid      0\n",
      "borough         1\n",
      "zone            1\n",
      "service_zone    2\n",
      "dtype: int64\n",
      "\n",
      "Calendar:\n",
      "date       0\n",
      "name       0\n",
      "special    0\n",
      "dtype: int64\n",
      "\n",
      "AN√ÅLISIS DE CALIDAD:\n",
      "   Total de viajes: 3,066,766\n",
      "   Viajes sin pickup location: 0\n",
      "   Viajes sin dropoff location: 0\n",
      "   Viajes sin passenger_count: 0\n",
      "\n",
      "ESTRATEGIAS DE LIMPIEZA:\n",
      "   Ubicaciones nulas: Eliminar (cr√≠tico para joins)\n",
      "   Passenger_count nulos: Rellenar con valor t√≠pico (1)\n",
      "   Tarifas nulas: Revisar caso por caso\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Paso 4. Join Principal - Trips con Zones"
   ],
   "metadata": {
    "id": "FvO-fxNoaCuN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "## === PRIMER JOIN: TRIPS + ZONES ===\n",
    "\n",
    "# 1. Hacer join de trips con zones para obtener informaci√≥n geogr√°fica\n",
    "print(\"Realizando join: trips + zones...\")\n",
    "trips_with_zones = trips.merge(zones,   # m√©todo principal para unir DataFrames\n",
    "                                left_on='pulocationid',   # columna de trips que contiene ID de zona de pickup\n",
    "                                right_on='locationid',  # columna de zones que contiene ID correspondiente\n",
    "                                how='left')       # tipo de join que mantiene todos los trips\n",
    "\n",
    "print(f\"   Registros antes del join: {len(trips)}\")\n",
    "print(f\"   Registros despu√©s del join: {len(trips_with_zones)}\")\n",
    "print(f\"   Nuevas columnas a√±adidas: {[col for col in trips_with_zones.columns if col not in trips.columns]}\")\n",
    "\n",
    "# 2. Verificar el resultado del join\n",
    "print(\"\\nVERIFICACI√ìN DEL JOIN:\")\n",
    "print(\"Conteo por Borough:\")\n",
    "print(trips_with_zones['borough'].value_counts())\n",
    "\n",
    "# 3. Verificar si hay valores nulos despu√©s del join\n",
    "null_after_join = trips_with_zones['borough'].isnull().sum()  # contar nulos en columna borough\n",
    "print(f\"\\nViajes sin borough asignado: {null_after_join}\")\n",
    "\n",
    "if null_after_join > 0:\n",
    "    print(\"   Algunos viajes no encontraron su zona correspondiente\")\n",
    "    print(\"   LocationIDs problem√°ticos:\")\n",
    "    problematic_ids = trips_with_zones[trips_with_zones['borough'].isnull()]['pulocationid'].unique()  # filtrar filas con nulos\n",
    "    print(f\"   {problematic_ids}\")\n",
    "\n",
    "# 4. Mostrar muestra del resultado\n",
    "print(\"\\nMUESTRA DEL DATASET INTEGRADO:\")\n",
    "print(trips_with_zones[['pulocationid', 'borough', 'zone', 'trip_distance', 'total_amount']].head())"
   ],
   "metadata": {
    "id": "eVKWWEIxaK0c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "13dace42-560b-499e-f71e-97c3d5a95653"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Realizando join: trips + zones...\n",
      "   Registros antes del join: 3066766\n",
      "   Registros despu√©s del join: 3066766\n",
      "   Nuevas columnas a√±adidas: ['locationid', 'borough', 'zone', 'service_zone']\n",
      "\n",
      "VERIFICACI√ìN DEL JOIN:\n",
      "Conteo por Borough:\n",
      "borough\n",
      "Manhattan        2715369\n",
      "Queens            286645\n",
      "Unknown            40116\n",
      "Brooklyn           18076\n",
      "Bronx               4162\n",
      "EWR                  410\n",
      "Staten Island        341\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Viajes sin borough asignado: 1647\n",
      "   Algunos viajes no encontraron su zona correspondiente\n",
      "   LocationIDs problem√°ticos:\n",
      "   [265]\n",
      "\n",
      "MUESTRA DEL DATASET INTEGRADO:\n",
      "   pulocationid    borough               zone  trip_distance  total_amount\n",
      "0           161  Manhattan     Midtown Center           0.97         14.30\n",
      "1            43  Manhattan       Central Park           1.10         16.90\n",
      "2            48  Manhattan       Clinton East           2.51         34.90\n",
      "3           138     Queens  LaGuardia Airport           1.90         20.85\n",
      "4           107  Manhattan           Gramercy           1.43         19.68\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paso 5: Segundo Join - Agregar Datos de *Calendario*"
   ],
   "metadata": {
    "id": "JsBPWOktbtiA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === SEGUNDO JOIN: TRIPS_ZONES + CALENDAR ===\n",
    "\n",
    "# 1. Hacer join con datos de calendario\n",
    "print(\"Realizando join: trips_zones + calendar...\")\n",
    "trips_complete = trips_with_zones.merge(calendar,   # mismo m√©todo de join que antes\n",
    "                                         left_on='pickup_date',   # columna de fecha que creamos en trips\n",
    "                                         right_on='date',  # columna de fecha en calendar\n",
    "                                         how='left')       # tipo que mantiene todos los trips aunque no haya evento especial\n",
    "\n",
    "print(f\"   Registros antes del join: {len(trips_with_zones)}\")\n",
    "print(f\"   Registros despu√©s del join: {len(trips_complete)}\")\n",
    "\n",
    "# 2. Crear flag de evento especial\n",
    "trips_complete['is_special_day'] = trips_complete['special'].fillna('False')  # m√©todo para rellenar nulos con valor por defecto\n",
    "\n",
    "print(\"\\nDISTRIBUCI√ìN DE D√çAS ESPECIALES:\")\n",
    "print(trips_complete['is_special_day'].value_counts())\n",
    "print(\"\\nEjemplos de eventos especiales:\")\n",
    "special_days = trips_complete[trips_complete['is_special_day'] == True]\n",
    "if len(special_days) > 0:\n",
    "    print(special_days[['pickup_date', 'special', 'borough']].drop_duplicates())\n",
    "else:\n",
    "    print(\"   No hay eventos especiales en este per√≠odo\")\n",
    "\n",
    "# 3. Mostrar dataset final integrado\n",
    "print(\"\\nDATASET FINAL INTEGRADO:\")\n",
    "print(f\"   Total registros: {len(trips_complete)}\")\n",
    "print(f\"   Total columnas: {len(trips_complete.columns)}\")\n",
    "print(f\"   Columnas principales: {['borough', 'zone', 'is_special_day', 'trip_distance', 'total_amount']}\")\n",
    "\n",
    "# 4. Verificar integridad de los datos finales\n",
    "print(\"\\nVERIFICACI√ìN FINAL:\")\n",
    "print(\"Datos faltantes por columna clave:\")\n",
    "key_columns = ['borough', 'zone', 'trip_distance', 'total_amount', 'is_special_day']\n",
    "for col in key_columns:\n",
    "    missing = trips_complete[col].isna().sum()  # verificar nulos en cada columna clave final\n",
    "    print(f\"   {col}: {missing} nulos\")"
   ],
   "metadata": {
    "id": "U6Xr-e23bzF1",
    "outputId": "05c09091-df16-4e2b-de05-429c284e2355",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Realizando join: trips_zones + calendar...\n",
      "   Registros antes del join: 3066766\n",
      "   Registros despu√©s del join: 3066766\n",
      "\n",
      "DISTRIBUCI√ìN DE D√çAS ESPECIALES:\n",
      "is_special_day\n",
      "False    3066766\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ejemplos de eventos especiales:\n",
      "   No hay eventos especiales en este per√≠odo\n",
      "\n",
      "DATASET FINAL INTEGRADO:\n",
      "   Total registros: 3066766\n",
      "   Total columnas: 28\n",
      "   Columnas principales: ['borough', 'zone', 'is_special_day', 'trip_distance', 'total_amount']\n",
      "\n",
      "VERIFICACI√ìN FINAL:\n",
      "Datos faltantes por columna clave:\n",
      "   borough: 1647 nulos\n",
      "   zone: 40116 nulos\n",
      "   trip_distance: 0 nulos\n",
      "   total_amount: 0 nulos\n",
      "   is_special_day: 0 nulos\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paso 6: Analisis por Borough"
   ],
   "metadata": {
    "id": "4JkOPRZVcBUc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === AN√ÅLISIS AGREGADO POR BOROUGH ===\n",
    "\n",
    "# 1. An√°lisis b√°sico por borough (con dataset grande)\n",
    "print(\"An√°lisis por Borough (procesando datos grandes)...\")\n",
    "borough_analysis = trips_complete.groupby(by='borough').agg({   # m√©todo para agrupar datos, por qu√© columna geogr√°fica?\n",
    "    'pulocationid': 'count',  # funci√≥n para contar n√∫mero de registros/viajes\n",
    "    'trip_distance': ['mean', 'std', 'median'],  # funci√≥n para promedio + desviaci√≥n + mediana\n",
    "    'total_amount': ['mean', 'std', 'median'],   # mismas estad√≠sticas para tarifas\n",
    "    'fare_amount': 'mean',     # solo promedio de tarifa base\n",
    "    'tip_amount': ['mean', 'median'],  # estad√≠sticas de propinas\n",
    "    'passenger_count': 'mean'  # funci√≥n para promedio de pasajeros\n",
    "}).round(2)\n",
    "\n",
    "# Aplanar columnas multi-nivel\n",
    "borough_analysis.columns = ['num_trips', 'avg_distance', 'std_distance', 'median_distance',\n",
    "                           'avg_total', 'std_total', 'median_total', 'avg_fare',\n",
    "                           'avg_tip', 'median_tip', 'avg_passengers']\n",
    "\n",
    "# Ordenar por n√∫mero de viajes\n",
    "borough_analysis = borough_analysis.sort_values(by='num_trips', ascending=False)  # m√©todo para ordenar DataFrame por una columna espec√≠fica\n",
    "\n",
    "print(\"\\nAN√ÅLISIS COMPLETO POR BOROUGH:\")\n",
    "print(borough_analysis)\n",
    "\n",
    "# 2. Calcular m√©tricas adicionales empresariales\n",
    "borough_analysis['revenue_per_km'] = (borough_analysis['avg_total'] /\n",
    "                                     borough_analysis['avg_distance']).round(2)\n",
    "borough_analysis['tip_rate'] = (borough_analysis['avg_tip'] /\n",
    "                               borough_analysis['avg_fare'] * 100).round(1)\n",
    "borough_analysis['market_share'] = (borough_analysis['num_trips'] /\n",
    "                                  borough_analysis['num_trips'].sum() * 100).round(1)\n",
    "\n",
    "print(\"\\nAN√ÅLISIS CON M√âTRICAS EMPRESARIALES:\")\n",
    "print(borough_analysis[['num_trips', 'market_share', 'revenue_per_km', 'tip_rate']])\n",
    "\n",
    "# 3. Encontrar insights\n",
    "print(\"\\nINSIGHTS PRINCIPALES:\")\n",
    "print(f\"   Borough con m√°s viajes: {borough_analysis.index[0]}\")\n",
    "print(f\"   Borough con viajes m√°s largos: {borough_analysis['avg_distance'].idxmax()}\")\n",
    "print(f\"   Borough con tarifas m√°s altas: {borough_analysis['avg_total'].idxmax()}\")\n",
    "print(f\"   Mejor revenue por km: {borough_analysis['revenue_per_km'].idxmax()}\")"
   ],
   "metadata": {
    "id": "h4hTs-g1cFeD",
    "outputId": "0d1859aa-5de9-47da-e053-1ab28a3e4160",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "An√°lisis por Borough (procesando datos grandes)...\n",
      "\n",
      "AN√ÅLISIS COMPLETO POR BOROUGH:\n",
      "               num_trips  avg_distance  std_distance  median_distance  \\\n",
      "borough                                                                 \n",
      "Manhattan        2715369          2.88        264.53             1.63   \n",
      "Queens            286645         12.32         14.42            11.24   \n",
      "Unknown            40116          7.57        144.96             2.64   \n",
      "Brooklyn           18076          5.68         70.86             3.45   \n",
      "Bronx               4162          5.30          6.34             3.10   \n",
      "EWR                  410          1.59          5.68             0.00   \n",
      "Staten Island        341         11.36         10.21            14.80   \n",
      "\n",
      "               avg_total  std_total  median_total  avg_fare  avg_tip  \\\n",
      "borough                                                                \n",
      "Manhattan          22.49      14.54         19.25     14.78     2.88   \n",
      "Queens             67.27      33.64         70.35     49.98     7.85   \n",
      "Unknown            38.08      30.41         25.38     26.44     4.82   \n",
      "Brooklyn           33.02      22.56         28.64     26.81     2.94   \n",
      "Bronx              34.54      33.26         29.70     30.24     0.78   \n",
      "EWR               104.38      62.75        118.55     87.99    12.44   \n",
      "Staten Island      62.53      44.92         67.80     48.74     1.32   \n",
      "\n",
      "               median_tip  avg_passengers  \n",
      "borough                                    \n",
      "Manhattan            2.66            1.33  \n",
      "Queens               8.18            1.38  \n",
      "Unknown              3.14            1.34  \n",
      "Brooklyn             0.60            1.08  \n",
      "Bronx                0.00            1.03  \n",
      "EWR                 10.00            1.58  \n",
      "Staten Island        0.00            1.12  \n",
      "\n",
      "AN√ÅLISIS CON M√âTRICAS EMPRESARIALES:\n",
      "               num_trips  market_share  revenue_per_km  tip_rate\n",
      "borough                                                         \n",
      "Manhattan        2715369          88.6            7.81      19.5\n",
      "Queens            286645           9.4            5.46      15.7\n",
      "Unknown            40116           1.3            5.03      18.2\n",
      "Brooklyn           18076           0.6            5.81      11.0\n",
      "Bronx               4162           0.1            6.52       2.6\n",
      "EWR                  410           0.0           65.65      14.1\n",
      "Staten Island        341           0.0            5.50       2.7\n",
      "\n",
      "INSIGHTS PRINCIPALES:\n",
      "   Borough con m√°s viajes: Manhattan\n",
      "   Borough con viajes m√°s largos: Queens\n",
      "   Borough con tarifas m√°s altas: EWR\n",
      "   Mejor revenue por km: EWR\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paso 7: Analisis por Borough y Dia especial"
   ],
   "metadata": {
    "id": "xiWBrvPydSdw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === AN√ÅLISIS COMPARATIVO: D√çAS NORMALES VS ESPECIALES ===\n",
    "\n",
    "# 1. An√°lisis por borough y tipo de d√≠a\n",
    "print(\"üìÖ An√°lisis: Borough + D√≠a Especial...\")\n",
    "borough_day_analysis = trips_complete.groupby(by=['borough', 'is_special_day']).agg({  # agrupar por DOS columnas: geograf√≠a y tipo de d√≠a\n",
    "    'pulocationid': 'count',  # funci√≥n para contar viajes\n",
    "    'trip_distance': 'mean',  # funci√≥n para promedio de distancia\n",
    "    'total_amount': 'mean'    # funci√≥n para promedio de tarifa\n",
    "}).round(2)\n",
    "\n",
    "borough_day_analysis.columns = ['num_trips', 'avg_distance', 'avg_total']\n",
    "\n",
    "print(\"\\nüìä AN√ÅLISIS BOROUGH + D√çA ESPECIAL:\")\n",
    "print(borough_day_analysis)\n",
    "\n",
    "# 2. Comparar d√≠as normales vs especiales\n",
    "print(\"\\nüîç COMPARACI√ìN D√çAS NORMALES VS ESPECIALES:\")\n",
    "\n",
    "# Pivotear para comparar f√°cilmente\n",
    "comparison = trips_complete.groupby(by='is_special_day').agg({  # agrupar solo por tipo de d√≠a para comparaci√≥n general\n",
    "    'trip_distance': 'mean',    # promedio de distancia por tipo de d√≠a\n",
    "    'total_amount': 'mean',     # promedio de tarifa por tipo de d√≠a\n",
    "    'pulocationid': 'count'     # conteo de viajes por tipo de d√≠a\n",
    "}).round(2)\n",
    "\n",
    "# Renombrar √≠ndices seg√∫n los valores √∫nicos encontrados\n",
    "unique_day_types = comparison.index.tolist()\n",
    "if len(unique_day_types) == 2:\n",
    "    comparison.index = ['D√≠a Normal', 'D√≠a Especial']\n",
    "elif len(unique_day_types) == 1:\n",
    "    if unique_day_types[0] in ['False', False]:\n",
    "        comparison.index = ['D√≠a Normal']\n",
    "    else:\n",
    "        comparison.index = ['D√≠a Especial']\n",
    "\n",
    "comparison.columns = ['Avg Distance', 'Avg Amount', 'Num Trips']\n",
    "\n",
    "print(comparison)\n",
    "\n",
    "# 3. Calcular diferencias porcentuales\n",
    "if len(comparison) > 1:\n",
    "    # Hay tanto d√≠as normales como especiales\n",
    "    if 'D√≠a Normal' in comparison.index and 'D√≠a Especial' in comparison.index:\n",
    "        normal_day = comparison.loc['D√≠a Normal']\n",
    "        special_day = comparison.loc['D√≠a Especial']\n",
    "\n",
    "        print(\"\\nIMPACTO DE D√çAS ESPECIALES:\")\n",
    "        distance_change = ((special_day['Avg Distance'] - normal_day['Avg Distance']) / normal_day['Avg Distance'] * 100)\n",
    "        amount_change = ((special_day['Avg Amount'] - normal_day['Avg Amount']) / normal_day['Avg Amount'] * 100)\n",
    "\n",
    "        print(f\"   Cambio en distancia promedio: {distance_change:+.1f}%\")\n",
    "        print(f\"   Cambio en tarifa promedio: {amount_change:+.1f}%\")\n",
    "    else:\n",
    "        print(\"\\nINFORMACI√ìN DE D√çAS:\")\n",
    "        for idx, row in comparison.iterrows():\n",
    "            print(f\"   {idx}: {row['Num Trips']:,} viajes, ${row['Avg Amount']:.2f} promedio\")\n",
    "else:\n",
    "    print(f\"\\nSOLO HAY {comparison.index[0]}:\")\n",
    "    print(f\"   Viajes: {comparison.iloc[0]['Num Trips']:,}\")\n",
    "    print(f\"   Distancia promedio: {comparison.iloc[0]['Avg Distance']:.2f} millas\")\n",
    "    print(f\"   Tarifa promedio: ${comparison.iloc[0]['Avg Amount']:.2f}\")\n",
    "    print(\"   No hay datos de d√≠as especiales para comparar en este per√≠odo\")"
   ],
   "metadata": {
    "id": "f94aCpfAdhGi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ed791a8c-3a58-4311-f5ff-7aa5bc976e3e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìÖ An√°lisis: Borough + D√≠a Especial...\n",
      "\n",
      "üìä AN√ÅLISIS BOROUGH + D√çA ESPECIAL:\n",
      "                              num_trips  avg_distance  avg_total\n",
      "borough       is_special_day                                    \n",
      "Bronx         False                4162          5.30      34.54\n",
      "Brooklyn      False               18076          5.68      33.02\n",
      "EWR           False                 410          1.59     104.38\n",
      "Manhattan     False             2715369          2.88      22.49\n",
      "Queens        False              286645         12.32      67.27\n",
      "Staten Island False                 341         11.36      62.53\n",
      "Unknown       False               40116          7.57      38.08\n",
      "\n",
      "üîç COMPARACI√ìN D√çAS NORMALES VS ESPECIALES:\n",
      "            Avg Distance  Avg Amount  Num Trips\n",
      "D√≠a Normal          3.85       27.02    3066766\n",
      "\n",
      "SOLO HAY D√≠a Normal:\n",
      "   Viajes: 3,066,766.0\n",
      "   Distancia promedio: 3.85 millas\n",
      "   Tarifa promedio: $27.02\n",
      "   No hay datos de d√≠as especiales para comparar en este per√≠odo\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 8: T√©cnicas para Datasets Grandes"
   ],
   "metadata": {
    "id": "i67wz1gFeR4a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === T√âCNICAS PARA TRABAJAR CON DATASETS GRANDES ===\n",
    "\n",
    "# 1. Sampling estrat√©gico para visualizaciones\n",
    "print(\"‚ö° Aplicando t√©cnicas para datasets grandes...\")\n",
    "\n",
    "# Si el dataset es muy grande, usar muestra para visualizaciones\n",
    "if len(trips_complete) > 50000:\n",
    "    print(f\"   üìä Dataset grande detectado: {len(trips_complete):,} registros\")\n",
    "    print(\"   üéØ Creando muestra estratificada para visualizaciones...\")\n",
    "\n",
    "    # Muestra proporcional por borough (simple aleatoria aqu√≠)\n",
    "    sample_size = min(10000, len(trips_complete) // 10)\n",
    "    trips_sample = trips_complete.sample(n=sample_size, random_state=42)  # m√©todo para tomar muestra aleatoria de n registros\n",
    "\n",
    "    print(f\"   ‚úÖ Muestra creada: {len(trips_sample):,} registros ({len(trips_sample)/len(trips_complete)*100:.1f}%)\")\n",
    "else:\n",
    "    trips_sample = trips_complete\n",
    "    print(\"   ‚ÑπÔ∏è Dataset peque√±o, usando datos completos para visualizaci√≥n\")\n",
    "\n",
    "# 2. An√°lisis de performance de joins\n",
    "print(\"\\nüìà AN√ÅLISIS DE PERFORMANCE:\")\n",
    "join_stats = {\n",
    "    'total_trips': len(trips),\n",
    "    'matched_zones': (trips_complete['borough'].notna()).sum(),\n",
    "    'match_rate': (trips_complete['borough'].notna().sum() / len(trips) * 100),\n",
    "    'unique_zones_used': trips_complete['zone'].nunique(),\n",
    "    'total_zones_available': len(zones),\n",
    "    'zone_coverage': (trips_complete['zone'].nunique() / len(zones) * 100)\n",
    "}\n",
    "\n",
    "for key, value in join_stats.items():\n",
    "    if 'rate' in key or 'coverage' in key:\n",
    "        print(f\"   {key}: {value:.1f}%\")\n",
    "    else:\n",
    "        print(f\"   {key}: {value:,}\")\n",
    "\n",
    "# 3. An√°lisis temporal avanzado (solo si hay suficientes datos)\n",
    "if len(trips_complete) > 1000:\n",
    "    print(\"\\nüìÖ AN√ÅLISIS TEMPORAL AVANZADO:\")\n",
    "\n",
    "    # An√°lisis por hora del d√≠a\n",
    "    trips_complete['pickup_hour'] = trips_complete['tpep_pickup_datetime'].dt.hour  # extraer hora de la fecha/hora\n",
    "    hourly_analysis = trips_complete.groupby(by='pickup_hour').agg({  # agrupar por hora del d√≠a\n",
    "        'pulocationid': 'count',     # contar viajes por hora (en min√∫sculas tras .str.lower())\n",
    "        'total_amount': 'mean',      # tarifa promedio por hora\n",
    "        'trip_distance': 'mean'      # distancia promedio por hora\n",
    "    }).round(2)\n",
    "\n",
    "    hourly_analysis.columns = ['trips_count', 'avg_amount', 'avg_distance']\n",
    "\n",
    "    print(\"   ‚è∞ Horas pico por n√∫mero de viajes:\")\n",
    "    peak_hours = hourly_analysis.sort_values(by='trips_count', ascending=False).head(3)  # ordenar por m√°s viajes, tomar top 3\n",
    "    for hour, stats in peak_hours.iterrows():\n",
    "        print(f\"      {hour:02d}:00 - {stats['trips_count']:,} viajes\")"
   ],
   "metadata": {
    "id": "e3UGHBqpe_-D",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7ab59e22-55b7-450a-cc2f-ba9829550802"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚ö° Aplicando t√©cnicas para datasets grandes...\n",
      "   üìä Dataset grande detectado: 3,066,766 registros\n",
      "   üéØ Creando muestra estratificada para visualizaciones...\n",
      "   ‚úÖ Muestra creada: 10,000 registros (0.3%)\n",
      "\n",
      "üìà AN√ÅLISIS DE PERFORMANCE:\n",
      "   total_trips: 3,066,766\n",
      "   matched_zones: 3,065,119\n",
      "   match_rate: 99.9%\n",
      "   unique_zones_used: 255\n",
      "   total_zones_available: 265\n",
      "   zone_coverage: 96.2%\n",
      "\n",
      "üìÖ AN√ÅLISIS TEMPORAL AVANZADO:\n",
      "   ‚è∞ Horas pico por n√∫mero de viajes:\n",
      "      18:00 - 215,889.0 viajes\n",
      "      17:00 - 209,493.0 viajes\n",
      "      15:00 - 196,424.0 viajes\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Paso 9: Analisis de Correlaciones"
   ],
   "metadata": {
    "id": "49pCdplmenuz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === AN√ÅLISIS DE CORRELACIONES NUM√âRICAS ===\n",
    "\n",
    "# Calcular correlaciones entre variables num√©ricas\n",
    "print(\"Calculando correlaciones entre variables num√©ricas...\")\n",
    "numeric_cols = ['trip_distance', 'total_amount', 'fare_amount', 'tip_amount']\n",
    "corr_matrix = trips_complete[numeric_cols].corr()  # m√©todo para calcular matriz de correlaci√≥n\n",
    "\n",
    "print(\"\\nMatriz de Correlaci√≥n:\")\n",
    "print(corr_matrix.round(3))\n",
    "\n",
    "print(\"\\nCorrelaciones m√°s fuertes:\")\n",
    "corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "\n",
    "corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "for var1, var2, corr in corr_pairs[:3]:\n",
    "    print(f\"   {var1} vs {var2}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\nINTERPRETACI√ìN DE CORRELACIONES:\")\n",
    "print(\"   > 0.7: Correlaci√≥n fuerte positiva\")\n",
    "print(\"   0.3-0.7: Correlaci√≥n moderada positiva\")\n",
    "print(\"   -0.3-0.3: Correlaci√≥n d√©bil\")\n",
    "print(\"   < -0.7: Correlaci√≥n fuerte negativa\")"
   ],
   "metadata": {
    "id": "iZSIOG1FdrTr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "39923ac6-e776-4403-e213-0971454342c4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculando correlaciones entre variables num√©ricas...\n",
      "\n",
      "Matriz de Correlaci√≥n:\n",
      "               trip_distance  total_amount  fare_amount  tip_amount\n",
      "trip_distance          1.000         0.016        0.016       0.011\n",
      "total_amount           0.016         1.000        0.980       0.710\n",
      "fare_amount            0.016         0.980        1.000       0.590\n",
      "tip_amount             0.011         0.710        0.590       1.000\n",
      "\n",
      "Correlaciones m√°s fuertes:\n",
      "   total_amount vs fare_amount: 0.980\n",
      "   total_amount vs tip_amount: 0.710\n",
      "   fare_amount vs tip_amount: 0.590\n",
      "\n",
      "INTERPRETACI√ìN DE CORRELACIONES:\n",
      "   > 0.7: Correlaci√≥n fuerte positiva\n",
      "   0.3-0.7: Correlaci√≥n moderada positiva\n",
      "   -0.3-0.3: Correlaci√≥n d√©bil\n",
      "   < -0.7: Correlaci√≥n fuerte negativa\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Responde estas preguntas despu√©s de completar el c√≥digo:\n",
    "\n",
    "1. ¬øQu√© diferencia hay entre un LEFT JOIN y un INNER JOIN?  \n",
    "   Un left join\n",
    "\n",
    "El left join prioriza la persistencia de los datos que tiene la tabla de la izquierda - Recaba los datos relacionados con la tabla de la izquierda\n",
    "\n",
    "El right join prioriza la persistencia de los datos que tiene la tabla de la derecha - Recaba los datos relacionados con la tabla de la derecha\n",
    "\n",
    "El inner join realzia una cconjunci√≥n de ambas tablas, por lo que no hay una que est√© m√°s ponderada que la otra - Recaba los datos relacionados con ambas tablas\n",
    "\n",
    "2. ¬øPor qu√© usamos LEFT JOIN en lugar de INNER JOIN para trips+zones?\n",
    "\n",
    "Esto se debe a que priorizamos los registros de viajes, antes que los de zonas, hay algunos registros cuyo PULocationID no est√°n relacionados a una zona.\n",
    "Si ponderamos la zona perder√≠amos viajes asociados a ellas.  \n",
    "\n",
    "3. ¬øQu√© problemas pueden surgir al hacer joins con datos de fechas?\n",
    "\n",
    "En caso de que el formato de las fechas sea distinto esto generar√≠a conflicto\n",
    "Tambi√©n pueden darse problemas debido a un desfase horario u errores de especificaci√≥n de las fechas\n",
    "A su vez las fechas que est√°n en nul generan p√©rdidades totales de registros en la consulta realizada\n",
    "\n",
    "En s√≠ todo recae en que el dato fecha es un dato que tiene demasiados formatos, y var√≠a mucho de dataset en dataset, primero se debe normalizar y estandarizar los datos, generando un formato √∫nico para realziar el an√°lisis.\n",
    "\n",
    "4. ¬øCu√°l es la ventaja de integrar m√∫ltiples fuentes de datos?\n",
    "\n",
    "La complejidad de los mismos, nos permite realizar un an√°lisis m√°s amplio, manejando un repertorio de datos m√°s grande.\n",
    "\n",
    "\n",
    "5. ¬øQu√© insights de negocio obtuviste del an√°lisis integrado?\n",
    "Concentraci√≥n de la demanda por zona. Un borough concentra la mayor cantidad de viajes (mayor market share), lo que indica d√≥nde priorizar flota y puntos de espera.\n",
    "\n",
    "Viajes m√°s largos fuera del centro. En los boroughs menos centrales la distancia promedio es mayor, √∫til para planificar tarifas, disponibilidad y tiempos de servicio.\n",
    "\n",
    "Eficiencia de ingresos. Hay diferencias claras en revenue por km entre boroughs; priorizar las zonas con mejor relaci√≥n ingreso/distancia mejora el margen.\n"
   ],
   "metadata": {
    "id": "peTazWt9kXim"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BONUS: Introducci√≥n a Prefect"
   ],
   "metadata": {
    "id": "2RSzJ1Xvvb6L"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 1: Setup B√°sico"
   ],
   "metadata": {
    "id": "sLQ5AH3svdvw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === SETUP PREFECT ===\n",
    "\n",
    "# Instalar Prefect (si no est√° instalado)\n",
    "!pip install prefect\n",
    "\n",
    "import prefect\n",
    "from prefect import task, flow, get_run_logger\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Prefect instalado y configurado\")\n",
    "print(f\"   Versi√≥n: {prefect.__version__}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EyDtYrYXviCX",
    "outputId": "130e60a3-0fd8-4b1b-f757-06ff93340588"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: prefect in /usr/local/lib/python3.12/dist-packages (3.4.14)\n",
      "Requirement already satisfied: aiosqlite<1.0.0,>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.21.0)\n",
      "Requirement already satisfied: alembic<2.0.0,>=1.7.5 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.16.4)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (4.10.0)\n",
      "Requirement already satisfied: apprise<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.9.4)\n",
      "Requirement already satisfied: asgi-lifespan<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.1.0)\n",
      "Requirement already satisfied: asyncpg<1.0.0,>=0.23 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.30.0)\n",
      "Requirement already satisfied: cachetools<7.0,>=5.3 in /usr/local/lib/python3.12/dist-packages (from prefect) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=8.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (8.2.1)\n",
      "Requirement already satisfied: cloudpickle<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (3.1.1)\n",
      "Requirement already satisfied: coolname<3.0.0,>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.2.0)\n",
      "Requirement already satisfied: cryptography>=36.0.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (43.0.3)\n",
      "Requirement already satisfied: dateparser<2.0.0,>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.2.2)\n",
      "Requirement already satisfied: docker<8.0,>=4.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (7.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.3.0)\n",
      "Requirement already satisfied: fastapi<1.0.0,>=0.111.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.116.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (2025.3.0)\n",
      "Requirement already satisfied: graphviz>=0.20.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.21)\n",
      "Requirement already satisfied: griffe<2.0.0,>=0.49.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.13.0)\n",
      "Requirement already satisfied: httpcore<2.0.0,>=1.0.5 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.0.9)\n",
      "Requirement already satisfied: httpx!=0.23.2,>=0.23 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]!=0.23.2,>=0.23->prefect) (0.28.1)\n",
      "Requirement already satisfied: humanize<5.0.0,>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (4.12.3)\n",
      "Requirement already satisfied: jinja2-humanize-extension>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.4.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.6 in /usr/local/lib/python3.12/dist-packages (from prefect) (3.1.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.32 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.33)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (4.25.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.27.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.36.0)\n",
      "Requirement already satisfied: orjson<4.0,>=3.7 in /usr/local/lib/python3.12/dist-packages (from prefect) (3.11.2)\n",
      "Requirement already satisfied: packaging<25.1,>=21.3 in /usr/local/lib/python3.12/dist-packages (from prefect) (25.0)\n",
      "Requirement already satisfied: pathspec>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.12.1)\n",
      "Requirement already satisfied: pendulum<4,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (3.1.0)\n",
      "Requirement already satisfied: prometheus-client>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.22.1)\n",
      "Requirement already satisfied: pydantic!=2.11.0,!=2.11.1,!=2.11.2,!=2.11.3,!=2.11.4,<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.11.7)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.33.2)\n",
      "Requirement already satisfied: pydantic-extra-types<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.10.5)\n",
      "Requirement already satisfied: pydantic-settings!=2.9.0,<3.0.0,>2.2.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from prefect) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify<9.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (8.0.4)\n",
      "Requirement already satisfied: python-socks<3.0,>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from python-socks[asyncio]<3.0,>=2.5.3->prefect) (2.7.2)\n",
      "Requirement already satisfied: pytz<2026,>=2021.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (2025.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from prefect) (6.0.2)\n",
      "Requirement already satisfied: readchar<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (4.2.1)\n",
      "Requirement already satisfied: rfc3339-validator<0.2.0,>=0.1.4 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.1.4)\n",
      "Requirement already satisfied: rich<15.0,>=11.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (13.9.4)\n",
      "Requirement already satisfied: ruamel-yaml>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.18.15)\n",
      "Requirement already satisfied: semver>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from prefect) (3.0.4)\n",
      "Requirement already satisfied: sniffio<2.0.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (1.3.1)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]<3.0.0,>=2.0->prefect) (2.0.43)\n",
      "Requirement already satisfied: toml>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.10.2)\n",
      "Requirement already satisfied: typer!=0.12.2,<0.17.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (4.14.1)\n",
      "Requirement already satisfied: uv>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.8.13)\n",
      "Requirement already satisfied: uvicorn!=0.29.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (0.35.0)\n",
      "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from prefect) (15.0.1)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2.0.0,>=1.7.5->prefect) (1.1.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.4.0->prefect) (3.10)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (2.32.4)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (2.0.0)\n",
      "Requirement already satisfied: markdown in /usr/local/lib/python3.12/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (3.8.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from apprise<2.0.0,>=1.1.0->prefect) (2025.8.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.1->prefect) (1.17.1)\n",
      "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser<2.0.0,>=1.1.1->prefect) (2024.11.6)\n",
      "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser<2.0.0,>=1.1.1->prefect) (5.3.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8.0,>=4.0->prefect) (2.5.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0.0,>=0.111.0->prefect) (0.47.2)\n",
      "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe<2.0.0,>=0.49.0->prefect) (0.4.6)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore<2.0.0,>=1.0.5->prefect) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]!=0.23.2,>=0.23->prefect) (4.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.6->prefect) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.32->prefect) (3.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.18.0->prefect) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.18.0->prefect) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.18.0->prefect) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.18.0->prefect) (0.27.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.27.0->prefect) (8.7.0)\n",
      "Requirement already satisfied: tzdata>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pendulum<4,>=3.0.0->prefect) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.11.0,!=2.11.1,!=2.11.2,!=2.11.3,!=2.11.4,<3.0.0,>=2.10.1->prefect) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.11.0,!=2.11.1,!=2.11.2,!=2.11.3,!=2.11.4,<3.0.0,>=2.10.1->prefect) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings!=2.9.0,<3.0.0,>2.2.1->prefect) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->prefect) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.12/dist-packages (from python-slugify<9.0,>=5.0->prefect) (1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0,>=11.0->prefect) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0,>=11.0->prefect) (2.19.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from ruamel-yaml>=0.17.0->prefect) (0.2.12)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3.0.0,>=2.0->sqlalchemy[asyncio]<3.0.0,>=2.0->prefect) (3.2.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer!=0.12.2,<0.17.0,>=0.12.0->prefect) (1.5.4)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.1->prefect) (2.22)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]!=0.23.2,>=0.23->prefect) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]!=0.23.2,>=0.23->prefect) (4.1.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.27.0->prefect) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0,>=11.0->prefect) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->apprise<2.0.0,>=1.1.0->prefect) (3.4.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->apprise<2.0.0,>=1.1.0->prefect) (3.3.1)\n",
      "Prefect instalado y configurado\n",
      "   Versi√≥n: 3.4.14\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 2: Convertir funciones a tasks"
   ],
   "metadata": {
    "id": "0THYCSQVvlPS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === TASKS SIMPLES PARA APRENDER PREFECT ===\n",
    "\n",
    "@task(name=\"Cargar Datos\", retries=2, retry_delay_seconds=3)\n",
    "def cargar_datos(url: str, tipo: str) -> pd.DataFrame:\n",
    "    \"\"\"Task simple para cargar cualquier tipo de datos\"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(f\"Cargando {tipo} desde: {url}\")\n",
    "\n",
    "    # Cargar seg√∫n el tipo\n",
    "    if tipo == \"trips\":\n",
    "        data = pd.read_parquet(url)  # funci√≥n para Parquet\n",
    "    elif tipo == \"zones\":\n",
    "        data = pd.read_csv(url)      # funci√≥n para CSV\n",
    "    else:  # calendar\n",
    "        data = pd.read_json(url)     # funci√≥n para JSON\n",
    "        data['date'] = pd.to_datetime(data['date']).dt.date  # convertir strings a fechas\n",
    "\n",
    "    logger.info(f\"{tipo} cargado: {data.shape[0]} filas\")\n",
    "    return data\n",
    "\n",
    "\n",
    "@task(name=\"Hacer Join Simple\")\n",
    "def hacer_join_simple(trips: pd.DataFrame, zones: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Task para hacer join b√°sico de trips + zones\"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Haciendo join simple...\")\n",
    "\n",
    "    # Normalizar columnas\n",
    "    trips.columns = trips.columns.str.lower()   # convertir a min√∫sculas\n",
    "    zones.columns = zones.columns.str.lower()   # misma transformaci√≥n\n",
    "\n",
    "    # Join b√°sico\n",
    "    resultado = trips.merge(zones,              # m√©todo para unir DataFrames\n",
    "                            left_on='pulocationid',   # columna de pickup location en trips\n",
    "                            right_on='locationid',    # columna de location en zones\n",
    "                            how='left')               # tipo de join que mantiene todos los trips\n",
    "\n",
    "    logger.info(f\"Join completado: {len(resultado)} registros\")\n",
    "    return resultado\n",
    "\n",
    "\n",
    "@task(name=\"An√°lisis R√°pido\")\n",
    "def analisis_rapido(data: pd.DataFrame) -> dict:\n",
    "    \"\"\"Task para an√°lisis b√°sico\"\"\"\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Haciendo an√°lisis b√°sico...\")\n",
    "\n",
    "    # Stats simples\n",
    "    stats = {\n",
    "        'total_registros': len(data),  # m√©todo para contar valores\n",
    "        'boroughs': data['borough'].value_counts().head(3).to_dict(),  # contar valores √∫nicos\n",
    "        'distancia_promedio': round(data['trip_distance'].mean(), 2),  # m√©todo para promedio\n",
    "        'tarifa_promedio': round(data['total_amount'].mean(), 2)       # m√©todo para promedio\n",
    "    }\n",
    "\n",
    "    logger.info(f\"An√°lisis completado: {stats['total_registros']} registros\")\n",
    "    return stats"
   ],
   "metadata": {
    "id": "P1rHRiIqvj3c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 3: Crear un flow simple"
   ],
   "metadata": {
    "id": "Lm4XuZcLvrn1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === FLOW PRINCIPAL (EL PIPELINE COMPLETO) ===\n",
    "\n",
    "@flow(name=\"Pipeline Simple NYC Taxi\")\n",
    "def pipeline_taxi_simple():\n",
    "    \"\"\"Flow simple que conecta todos los tasks\"\"\"\n",
    "\n",
    "    logger = get_run_logger()\n",
    "    logger.info(\"Iniciando pipeline simple...\")\n",
    "\n",
    "    # URLs de datos\n",
    "    trips_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\"\n",
    "    zones_url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\"\n",
    "\n",
    "    # PASO 1: Cargar datos (con retry autom√°tico si falla)\n",
    "    logger.info(\"Paso 1: Cargando datos...\")\n",
    "    trips = cargar_datos(trips_url, \"trips\")    # tipo de datos = trips\n",
    "    zones = cargar_datos(zones_url, \"zones\")    # tipo de datos = zones\n",
    "\n",
    "    # PASO 2: Hacer join\n",
    "    logger.info(\"Paso 2: Haciendo join...\")\n",
    "    data_unida = hacer_join_simple(trips, zones)\n",
    "\n",
    "    # PASO 3: An√°lisis b√°sico\n",
    "    logger.info(\"Paso 3: Analizando...\")\n",
    "    resultados = analisis_rapido(data_unida)\n",
    "\n",
    "    # PASO 4: Mostrar resultados\n",
    "    logger.info(\"Pipeline completado!\")\n",
    "    logger.info(f\"Resultados: {resultados}\")\n",
    "\n",
    "    return resultados"
   ],
   "metadata": {
    "id": "MVtX17WfvsP_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paso 4: Ejecutar el Pipeline"
   ],
   "metadata": {
    "id": "D5MOR7UpvujO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# === EJECUTAR EL PIPELINE ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Ejecutando pipeline simple...\")\n",
    "\n",
    "    # Ejecutar el flow\n",
    "    resultado = pipeline_taxi_simple()   # nombre de la funci√≥n del flow\n",
    "\n",
    "    print(\"\\nüìä RESULTADOS FINALES:\")\n",
    "    print(f\" Total registros: {resultado['total_registros']}\")\n",
    "    print(f\" Distancia promedio: {resultado['distancia_promedio']} millas\")\n",
    "    print(f\" Tarifa promedio: ${resultado['tarifa_promedio']}\")\n",
    "\n",
    "    print(\"\\nüèôÔ∏è Top 3 Boroughs:\")\n",
    "    for borough, count in resultado['boroughs'].items():  # clave del diccionario que contiene boroughs\n",
    "        print(f\" {borough}: {count} viajes\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "Ok-tq2v6vwXO",
    "outputId": "eeced601-13fe-49b0-c523-ca8e5c15ae38"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üöÄ Ejecutando pipeline simple...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:19.946 | \u001b[36mINFO\u001b[0m    | prefect - Starting temporary server on \u001b[94mhttp://127.0.0.1:8916\u001b[0m\n",
       "See \u001b[94mhttps://docs.prefect.io/v3/concepts/server#how-to-guides\u001b[0m for more information on running a dedicated Prefect server.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:19.946 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect - Starting temporary server on <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:8916</span>\n",
       "See <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://docs.prefect.io/v3/concepts/server#how-to-guides</span> for more information on running a dedicated Prefect server.\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:20.572 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Beginning flow run\u001b[35m 'bouncy-jaguar'\u001b[0m for flow\u001b[1;35m 'Pipeline Simple NYC Taxi'\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:20.572 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Pipeline Simple NYC Taxi'</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:20.584 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Iniciando pipeline simple...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:20.584 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Iniciando pipeline simple...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:20.586 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Paso 1: Cargando datos...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:20.586 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Paso 1: Cargando datos...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:20.836 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-f06' - Cargando trips desde: \u001b[94mhttps://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:20.836 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-f06' - Cargando trips desde: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.571 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-f06' - trips cargado: 3066766 filas\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.571 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-f06' - trips cargado: 3066766 filas\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.594 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-f06' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.594 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-f06' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.849 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-e5e' - Cargando zones desde: \u001b[94mhttps://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.849 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-e5e' - Cargando zones desde: <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.891 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-e5e' - zones cargado: 265 filas\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.891 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-e5e' - zones cargado: 265 filas\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.900 | \u001b[36mINFO\u001b[0m    | Task run 'Cargar Datos-e5e' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.900 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Cargar Datos-e5e' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:23.912 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Paso 2: Haciendo join...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:23.912 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Paso 2: Haciendo join...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:29.043 | \u001b[36mINFO\u001b[0m    | Task run 'Hacer Join Simple-c2a' - Haciendo join simple...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:29.043 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Hacer Join Simple-c2a' - Haciendo join simple...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:31.600 | \u001b[36mINFO\u001b[0m    | Task run 'Hacer Join Simple-c2a' - Join completado: 3066766 registros\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:31.600 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Hacer Join Simple-c2a' - Join completado: 3066766 registros\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:31.628 | \u001b[36mINFO\u001b[0m    | Task run 'Hacer Join Simple-c2a' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:31.628 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Hacer Join Simple-c2a' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:31.638 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Paso 3: Analizando...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:31.638 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Paso 3: Analizando...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:36.913 | \u001b[36mINFO\u001b[0m    | Task run 'An√°lisis R√°pido-6bd' - Haciendo an√°lisis b√°sico...\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:36.913 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'An√°lisis R√°pido-6bd' - Haciendo an√°lisis b√°sico...\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:37.536 | \u001b[36mINFO\u001b[0m    | Task run 'An√°lisis R√°pido-6bd' - An√°lisis completado: 3066766 registros\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:37.536 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'An√°lisis R√°pido-6bd' - An√°lisis completado: 3066766 registros\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:37.553 | \u001b[36mINFO\u001b[0m    | Task run 'An√°lisis R√°pido-6bd' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:37.553 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'An√°lisis R√°pido-6bd' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:37.562 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Pipeline completado!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:37.562 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Pipeline completado!\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:37.573 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Resultados: {'total_registros': 3066766, 'boroughs': {'Manhattan': 2715369, 'Queens': 286645, 'Unknown': 40116}, 'distancia_promedio': np.float64(3.85), 'tarifa_promedio': np.float64(27.02)}\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:37.573 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Resultados: {'total_registros': 3066766, 'boroughs': {'Manhattan': 2715369, 'Queens': 286645, 'Unknown': 40116}, 'distancia_promedio': np.float64(3.85), 'tarifa_promedio': np.float64(27.02)}\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "13:45:37.874 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'bouncy-jaguar'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">13:45:37.874 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'bouncy-jaguar'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "üìä RESULTADOS FINALES:\n",
      " Total registros: 3066766\n",
      " Distancia promedio: 3.85 millas\n",
      " Tarifa promedio: $27.02\n",
      "\n",
      "üèôÔ∏è Top 3 Boroughs:\n",
      " Manhattan: 2715369 viajes\n",
      " Queens: 286645 viajes\n",
      " Unknown: 40116 viajes\n"
     ]
    }
   ]
  }
 ]
}